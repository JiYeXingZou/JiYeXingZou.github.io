<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Izumi Sagiri</title>
  
  <subtitle>个人博客</subtitle>
  <link href="https://jiyexingzou.github.io/atom.xml" rel="self"/>
  
  <link href="https://jiyexingzou.github.io/"/>
  <updated>2025-12-31T14:16:06.345Z</updated>
  <id>https://jiyexingzou.github.io/</id>
  
  <author>
    <name>Izumi Sagiri</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2025年终总结</title>
    <link href="https://jiyexingzou.github.io/2025/12/31/2025%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>https://jiyexingzou.github.io/2025/12/31/2025%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</id>
    <published>2025-12-31T13:03:04.000Z</published>
    <updated>2025-12-31T14:16:06.345Z</updated>
    
    <content type="html"><![CDATA[<h1>总结</h1><p>转眼间2025年就要过去了，是时候来一个年终总结了<br>这一年发生了很多事情，有了两篇论文，找到了实习，遇见了很多人。<br>时间真的过的好快。<br>我自己对于2025年的评价呢，我认为，真的很幸福且充实。<br>大二下的时候，组建了打比赛的团队。<br>大家真的很努力，而且那个时候虽然事情很多很紧张，但是现在一回想，真的做了很多事情。<br>暑假的时候，吵吵合合，也是最后调整过来了。<br>现在已经适应了两个人的生活，感觉自己不再那么自私了。<br>感觉自己离自己的目标又更近一步了。<br>大三上，前面在焦虑和迷茫中度过<br>10月份投的老师，没有了回信，陷入了深深的自我否定<br>还好12月份，勇敢了一把，终于让实习有了着落。<br>我有成熟一点了吗？</p><h1>未来的展望和一些想法</h1><p>明年想要好好去做这段实习，好好复习考研，我真的很害怕我会懈怠。</p><h2 id="实习">实习</h2><p>尽量参与到发表论文，真正获得提升</p><h2 id="明年考研需要做的：">明年考研需要做的：</h2><h3 id="1-6月底">1~6月底</h3><p>过完专业课的一轮和数学三本书<br>408看完网课，做王道练习题，做一个梳理<br>数一，过完三本书，做一些课后练习题<br>英语，过完两轮单词</p><h3 id="7-12月">7~12月</h3><p>二轮，刷真题，九月份开政治</p><h1>尾声</h1><p>2025可能是我本科阶段最后一个好好体验大学生活的时候了，得好好的成为大人啊<br>我感觉我的大学前两年，很多时候没有真正学到东西。后面我能改进一些吗？<br>最后，放一张纱雾镇楼<br><img src="/2025/12/31/2025%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/%E5%92%8C%E6%B3%89%E7%BA%B1%E9%9B%BE-138780755.png" alt="alt text"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;总结&lt;/h1&gt;
&lt;p&gt;转眼间2025年就要过去了，是时候来一个年终总结了&lt;br&gt;
这一年发生了很多事情，有了两篇论文，找到了实习，遇见了很多人。&lt;br&gt;
时间真的过的好快。&lt;br&gt;
我自己对于2025年的评价呢，我认为，真的很幸福且充实。&lt;br&gt;
大二下的时候，组建了打比</summary>
      
    
    
    
    
    <category term="总结" scheme="https://jiyexingzou.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
    <category term="年终" scheme="https://jiyexingzou.github.io/tags/%E5%B9%B4%E7%BB%88/"/>
    
    <category term="生活" scheme="https://jiyexingzou.github.io/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客图床配置完全指南</title>
    <link href="https://jiyexingzou.github.io/2025/12/30/Hexo%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E9%85%8D%E7%BD%AE%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/"/>
    <id>https://jiyexingzou.github.io/2025/12/30/Hexo%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E9%85%8D%E7%BD%AE%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</id>
    <published>2025-12-30T08:38:52.000Z</published>
    <updated>2025-12-30T08:40:10.242Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在使用 Hexo 搭建博客时，很多小伙伴都会遇到两个问题：</p><ol><li><strong>本地图片占用空间过大</strong>：图片直接保存在本地和 GitHub 仓库，会导致仓库体积膨胀</li><li><strong>VSCode 粘贴图片不便</strong>：每次写博客时，粘贴的图片无法自动保存到对应的文章文件夹</li></ol><p>本文将介绍如何使用图床服务来优雅地解决这些问题。</p><h2 id="什么是图床？">什么是图床？</h2><p>图床是一种图片存储和托管服务，可以：</p><ul><li>节省本地和 GitHub 仓库空间</li><li>加快图片加载速度（配合 CDN）</li><li>支持图片外链，在 Markdown 中直接引用</li><li>方便图片管理和备份</li></ul><h2 id="解决方案概述">解决方案概述</h2><p>我们将使用以下工具组合：</p><ul><li><strong>PicList</strong>：强大的图床上传工具，支持多种图床服务</li><li><strong><a href="http://SM.MS">SM.MS</a></strong>：免费图床服务（也可选择其他图床）</li><li><strong>VSCode 插件</strong>：实现编辑器内一键上传图片</li></ul><h2 id="详细配置步骤">详细配置步骤</h2><h3 id="第一步：安装-PicList">第一步：安装 PicList</h3><ol><li>访问 <a href="https://github.com/Kuingsmile/PicList/releases">PicList Releases</a></li><li>下载最新的 Windows 安装包（<code>PicList-Setup-x.x.x.exe</code>）</li><li>双击安装，按提示完成安装</li></ol><p><strong>PicList 支持的图床服务：</strong></p><ul><li><a href="http://SM.MS">SM.MS</a>（免费，推荐新手）</li><li>imgloc（免费，无需注册）</li><li>阿里云 OSS（稳定，有免费额度）</li><li>腾讯云 COS（稳定，有免费额度）</li><li>GitHub（免费，但国内访问较慢）</li></ul><h3 id="第二步：注册并配置-SM-MS-图床">第二步：注册并配置 <a href="http://SM.MS">SM.MS</a> 图床</h3><ol><li>访问 <a href="https://sm.ms/home/register">SM.MS 注册页面</a> 注册账号</li><li>登录后访问 <a href="https://sm.ms/home/apitoken">API Token 页面</a></li><li>点击生成 API Token，复制保存</li><li>打开 PicList 应用</li><li>点击 <strong>图床设置</strong> → <strong><a href="http://SM.MS">SM.MS</a> 图床</strong></li><li>填入 API Token，点击确定</li></ol><h3 id="第三步：安装-VSCode-插件">第三步：安装 VSCode 插件</h3><p>在 VSCode 中打开博客项目：</p><ol><li>按 <code>Ctrl+Shift+X</code> 打开扩展面板</li><li>搜索 <strong>“Image/Picture Uploader (PicList)”</strong></li><li>点击安装</li></ol><h3 id="第四步：使用方法">第四步：使用方法</h3><p>配置完成后，在写博客时非常方便：</p><h4 id="方式一：剪贴板上传（最常用）">方式一：剪贴板上传（最常用）</h4><ol><li>截图或复制图片到剪贴板</li><li>在 Markdown 文件中按 <code>Ctrl+Alt+U</code></li><li>图片自动上传并插入 Markdown 链接</li></ol><h4 id="方式二：拖拽上传">方式二：拖拽上传</h4><p>直接拖拽图片到编辑器，自动上传并插入链接</p><h4 id="方式三：右键上传本地图片">方式三：右键上传本地图片</h4><p>右键点击图片文件，选择 “Upload Image with PicList”</p><h2 id="其他图床推荐">其他图床推荐</h2><h3 id="imgloc">imgloc</h3><ul><li><strong>优点</strong>：完全免费，无需注册</li><li><strong>缺点</strong>：稳定性稍差</li><li><strong>适用场景</strong>：临时图片存储，测试使用</li></ul><h3 id="阿里云-OSS">阿里云 OSS</h3><ul><li><strong>优点</strong>：稳定快速，国内访问速度快</li><li><strong>免费额度</strong>：40GB 存储，每月 5GB 流量</li><li><strong>适用场景</strong>：生产环境，追求稳定性</li></ul><h3 id="腾讯云-COS">腾讯云 COS</h3><ul><li><strong>优点</strong>：稳定快速，CDN 加速</li><li><strong>免费额度</strong>：50GB 存储（6 个月）</li><li><strong>适用场景</strong>：生产环境，国内用户为主</li></ul><h2 id="常见问题">常见问题</h2><h3 id="Q-图片上传失败怎么办？">Q: 图片上传失败怎么办？</h3><p>A: 检查以下几点：</p><ul><li>网络连接是否正常</li><li>API Token 是否正确</li><li>图床服务是否可用</li></ul><h3 id="Q-如何批量上传图片？">Q: 如何批量上传图片？</h3><p>A: 在 PicList 主界面可以批量选择图片上传，然后复制生成的 Markdown 链接</p><h3 id="Q-如何管理已上传的图片？">Q: 如何管理已上传的图片？</h3><p>A: 在图床服务的管理后台（如 <a href="http://SM.MS">SM.MS</a>）或 PicList 的相册管理中可以查看和删除</p><h2 id="优化建议">优化建议</h2><ol><li><strong>图片压缩</strong>：上传前使用 <a href="https://tinypng.com/">TinyPNG</a> 压缩图片</li><li><strong>定期清理</strong>：定期在图床后台删除不再使用的图片</li><li><strong>备份数据</strong>：重要图片建议备份到本地或云盘</li><li><strong>使用 CDN</strong>：如果使用阿里云 OSS 或腾讯云 COS，可以开启 CDN 加速</li></ol><h2 id="效果对比">效果对比</h2><p><strong>使用图床前：</strong></p><ul><li>本地图片：2MB+ 每张</li><li>GitHub 仓库：几百 MB</li><li>图片加载：较慢</li></ul><p><strong>使用图床后：</strong></p><ul><li>本地图片：0</li><li>GitHub 仓库：仅 Markdown 文本</li><li>图片加载：快速（配合 CDN）</li></ul><h2 id="总结">总结</h2><p>通过配置图床服务，我们优雅地解决了 Hexo 博客的图片管理问题：</p><ul><li>释放了本地和仓库空间</li><li>实现了 VSCode 一键上传图片</li><li>提升了博客加载速度</li></ul><p>如果你在配置过程中遇到问题，欢迎在评论区交流！</p><h2 id="参考链接">参考链接</h2><ul><li><a href="https://github.com/Kuingsmile/PicList">PicList GitHub</a></li><li><a href="https://sm.ms/">SM.MS 官网</a></li><li><a href="https://hexo.io/">Hexo 官方文档</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;在使用 Hexo 搭建博客时，很多小伙伴都会遇到两个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;本地图片占用空间过大&lt;/strong&gt;：图片直接保存在本地和 GitHub 仓库，会导致仓库体积膨胀&lt;/li&gt;
&lt;li&gt;&lt;stron</summary>
      
    
    
    
    <category term="技术教程" scheme="https://jiyexingzou.github.io/categories/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/"/>
    
    
    <category term="Hexo" scheme="https://jiyexingzou.github.io/tags/Hexo/"/>
    
    <category term="博客优化" scheme="https://jiyexingzou.github.io/tags/%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96/"/>
    
    <category term="图床" scheme="https://jiyexingzou.github.io/tags/%E5%9B%BE%E5%BA%8A/"/>
    
  </entry>
  
  <entry>
    <title>12.14-25日论文学习报告</title>
    <link href="https://jiyexingzou.github.io/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/"/>
    <id>https://jiyexingzou.github.io/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/</id>
    <published>2025-12-25T15:10:00.000Z</published>
    <updated>2025-12-30T08:45:36.592Z</updated>
    
    <content type="html"><![CDATA[<p><strong>报告人:王子通 | 2025/12/25</strong></p><h1>MatchTime 系列论文深度笔记</h1><h1>第一篇论文 MatchTime: Towards Automatic Soccer Game Commentary Generation</h1><h2 id="核心痛点：消失的“16秒”">核心痛点：消失的“16秒”</h2><p>在足球视频领域，传统的解说词数据存在严重的<strong>音画不同步</strong>。由于原始数据大多抓取自实时文字直播，解说词往往比实际进球画面晚了 <strong>16.63 秒</strong>甚至更多。如果直接用这种“脏数据”训练，AI 只会学会“马后炮”。</p><hr><h2 id="第一章：数据治本——如何通过数学实现“降维打击”">第一章：数据治本——如何通过数学实现“降维打击”</h2><p>论文的核心贡献在于 <strong>Section 3.2 (Temporal Alignment Pipeline)</strong>，它展示了如何用一套自动化的管线将滞后的文本“拽”回正确的帧。</p><h3 id="1-亲和力矩阵-Affinity-Matrix-：连连看的底牌">1. 亲和力矩阵 (Affinity Matrix)：连连看的底牌</h3><p>为了对齐视频帧（Visual Frames）和解说词（Text Captions），作者引入了 <strong>Affinity Matrix  $\mathbb{A}$</strong>。</p><ul><li><strong>它是怎么来的？</strong> 假设视频有$n$ 帧，文本有 $k$ 句，矩阵的大小就是$k \times n$ 。</li></ul><h3 id="核心公式推导：亲和力矩阵-Affinity-Matrix">核心公式推导：亲和力矩阵 (Affinity Matrix)</h3><p>在计算视频帧 $V_j$ 与文本 $C_i$ 的相似度时，公式表达为：</p><p>$$\mathbb{A}[i, j] = \frac{C_i \cdot V_j^T}{||C_i|| \cdot ||V_j|| \cdot \tau}$$</p><p><strong>公式拆解：</strong></p><ul><li><strong>分子 ($C_i \cdot V_j^T$)</strong>：特征向量的点积，衡量方向一致性。</li><li><strong>分母 ($||C_i|| \cdot ||V_j||$)</strong>：$L_2$ 范数归一化，确保计算的是<strong>余弦相似度</strong>。</li><li><strong>$\tau$</strong>：温度参数，用来控制相似度分布的平滑度。</li><li><strong>深度解析</strong>：</li><li>** 是什么？** 这是向量的 ** 范数**（模长）。之所以要除以它，是为了进行<strong>归一化</strong>，将计算锁定为<strong>余弦相似度</strong>。我们只关心文本和画面的“语义方向”是否一致，而不关心特征向量本身的绝对大小。</li><li><strong>为什么要算这个？</strong> 通过寻找矩阵每一行中的最大值（），模型能自动锁死每一句解说词对应的“高光时刻”。</li></ul><hr><h2 id="第二章：模型架构——MatchVoice-的“翻译”逻辑">第二章：模型架构——MatchVoice 的“翻译”逻辑</h2><p>MatchVoice 的本质是一个<strong>多模态大模型 (MLLM)</strong>。它通过一套精密设计的组件，将视频“翻译”成文字。</p><h3 id="1-为什么视觉编码器-Visual-Encoder-要冻结？">1. 为什么视觉编码器 (Visual Encoder) 要冻结？</h3><p>在架构图中，你会看到视觉部分（如 CLIP 或 Baidu 特征）被打上了“雪花”图标（Frozen）。</p><ul><li><strong>策略</strong>：冻结预训练好的编码器可以保持其强大的通用特征提取能力，同时大幅降低训练成本。</li></ul><h3 id="2-Learnable-Queries-Attention：精准探测器">2. Learnable Queries &amp; Attention：精准探测器</h3><ul><li><strong>Learnable Queries</strong>：它们不是来自视频，而是模型内置的“探测员”。</li><li><strong>自注意力 (Self-Attention)</strong>：让这群“探测员”在出发前先开个会，分工合作（比如有的看人，有的看球）。</li><li><strong>交叉注意力 (Cross-Attention)</strong>：这是关键！探测员拿着清单去视频特征（超市货架）里取货，把散落在时空中的信息吸收到 Query 向量中。<br><img src="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/image-4.png" alt="alt text"></li></ul><h3 id="3-从投影到生成：MLP-与-Prefix-Tokens">3. 从投影到生成：MLP 与 Prefix Tokens</h3><ul><li><strong>MLP 的翻译官作用</strong>：视觉特征与 LLM 的维度往往不匹配。<strong>MLP (Projection Layer)</strong> 就像转换插头，将视觉特征投影到 LLM 能听懂的空间。</li><li><strong>Prefix Tokens (紫色方块)</strong>：这是 MLP 输出的唯一成果。它们作为“视觉前缀”喂给 LLM（如 LLaMA-3）。</li><li><strong>生成逻辑:$C = \Psi_{dec}(\Psi_{proj}(F))$。</strong>：。LLM 接收到视觉前缀后，开始顺着这个背景一个词一个词地吐出蓝色的 <strong>Commentary Tokens</strong>。</li></ul><hr><h2 id="第三章：评估的“金标准”——SN-Caption-test-align">第三章：评估的“金标准”——SN-Caption-test-align</h2><p>为了证明 AI 真的看懂了球，作者没有使用模糊的原始数据进行评估，而是打造了 <strong>SN-Caption-test-align</strong>。</p><ul><li><strong>本质</strong>：这是对 SoccerNet-Caption 的<strong>人工精修版</strong>。</li><li><strong>意义</strong>：它不仅是一个数据集，更是一个“公正的考官”。只有在时间戳绝对准确的考卷上拿到高分（如 <strong>CIDEr</strong> 分数的暴涨），才能证明对齐管线的有效性。</li></ul><hr><ul><li><strong>Baidu 特征最强</strong>：实验证明，相比通用的 CLIP，这种在足球领域“深造”过的模型（Baidu Soccer Embeddings）作为视觉编码器效果最佳。</li><li><strong>数据 &gt; 模型</strong>：即便使用基础的 ResNet，只要用了对齐后的 MatchTime 数据集，表现甚至能超越在脏数据上跑的高级模型。</li></ul><hr><h2 id="第二篇论文-Towards-Universal-Soccer-Video-Understanding">第二篇论文 Towards Universal Soccer Video Understanding</h2><p>第二篇论文在第一篇论文的基础上提出了SoccerReplay-1988数据集。<br>并且提出了足球专用的解码器MatchVison</p><h3 id="SoccerReplay-19886-Dataset">SoccerReplay-19886 Dataset</h3><p>这篇文章阐述了这个作者是如何做这个数据集的，将视频分为上下两场，从starting at kick off开始。并且采用第一篇文章的MatchTime的对齐方式，通过手动进行人工对齐</p><p><img src="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/image-5.png" alt="alt text"></p><h3 id="对于模型我自己的理解">对于模型我自己的理解:</h3><p>本质上就是一个改进的video transformer</p><h4 id="Token-Embedding">Token Embedding</h4><p><strong>空间切分：</strong> 每一帧图像 $ i $ 被切分成 $ M $ 个不重叠的小方块（Patches）。这就像把一张照片剪成方格阵列。</p><p><strong>线性映射 ($\Phi_{Emb}$)：</strong> 每个小方块被拉平并转换成一个维度为 $D$ 的向量。</p><p><strong>双重位置编码 (Position Embedding)：</strong> 这是关键。</p><ul><li><strong>空间位置编码 ($e_s^{pos}$)</strong>：告诉模型这个方块在画面的哪个位置（左上还是右下）。</li><li><strong>时间位置编码 ($e_t^{pos}$)</strong>：在处理完整个视频序列后叠加，告诉模型这一组特征属于视频的第几秒。</li></ul><p><strong>[CLS] 标记：</strong> 每一帧都会加入一个特殊的 <code>[cls]</code> 标记，专门用来汇总这一帧的全局信息。</p><h4 id="时空注意力模块">时空注意力模块</h4><p><strong>时间自注意力 ($\phi_t$)：</strong></p><ul><li><strong>操作：</strong> 只在不同帧的<strong>相同空间位置</strong>的 Token 之间进行计算。</li><li><strong>目的：</strong> 追踪动作。例如，第1帧里的足球在左边，第2帧里的足球移动到了中间，时间注意力负责捕捉这个“移动”轨迹。</li></ul><p><strong>空间自注意力 ($\phi_s$)：</strong></p><ul><li><strong>操作：</strong> 只在<strong>同一帧内部</strong>的不同 Token 之间进行计算。</li><li><strong>目的：</strong> 理解布局。例如，识别出这一帧画面里哪是球员、哪是球门、哪是裁判。</li></ul><p><strong>交替堆叠 ($K$ 次)：</strong> 通过多次交替循环，模型既能看清每一帧的细节，又能理解动作在时间上的逻辑。</p><h4 id="聚合层-Aggregation-Layer">聚合层(Aggregation Layer)</h4><p>在经过复杂的注意力计算后，模型需要把海量的数据“浓缩”成一个简洁的特征向量，供下游任务使用。</p><ul><li><strong>空间聚合：</strong> 利用聚合层 $\Phi_{Agg}$，将每一帧中散落在各个 Patch 里的信息，全部压缩到该帧的 <code>[cls]</code> 标记中（得到 $\hat{F}_i^{CLS}$）。</li><li><strong>最终表示 ($F_V$)：</strong> 将所有帧的 <code>[cls]</code> 标记拼接起来。<ul><li><strong>结果：</strong> 得到的 $F_V$ 是一个矩阵，它每一行代表一帧的精华，整组矩阵代表了整个视频片段的精华。</li></ul></li></ul><h3 id="预训练层">预训练层</h3><h3 id="监督分类-Supervised-Classification-mathcal-L-sup"><strong>监督分类 (Supervised Classification, $\mathcal{L}_{sup}$)</strong></h3><ul><li><strong>做法：</strong> 将提取出的视频特征 $F_V$ 通过一个<strong>时间自注意力层</strong>，汇总到一个可学习的 <code>[cls]</code> 标记中。</li><li><strong>计算：</strong> 这个标记被输入线性分类器，使用<strong>交叉熵损失 (Cross-Entropy Loss)</strong> 进行训练。</li><li><strong>目的：</strong> 让模型学会“看图识事”，即直接根据画面判断这是进球还是犯规。</li></ul><h3 id="视频-语言对比学习-Video-Language-Contrastive-Learning-mathcal-L-contra"><strong>视频-语言对比学习 (Video-Language Contrastive Learning, $\mathcal{L}_{contra}$)</strong></h3><ul><li><strong>做法：</strong> 对视频特征进行平均池化得到 $F_V^{Avg}$，同时用文本编码器处理解说词 $C$。</li><li><strong>创新点：</strong> 借鉴了 <strong>SigLIP</strong> 的损失函数。</li><li><strong>正样本优化：</strong> 针对足球比赛中经常出现高度相似的解说（如“比赛开始”），模型将同一批次中相似度高的文本都视为正样本，增强了鲁棒性。</li><li><strong>目的：</strong> 建立视觉与文本的语义联系，为下游的解说生成任务打好基础。</li></ul><h3 id="疑问：">疑问：</h3><h4 id="为什么是监督分类？">为什么是监督分类？</h4><h3 id="1-足球语义的复杂性与明确性">1. 足球语义的复杂性与明确性</h3><ul><li><strong>语义明确：</strong> 足球比赛中的关键事件（如进球、黄牌、换人）都有非常明确的官方定义和边界。</li><li><strong>监督优势：</strong> 监督分类通过使用专家标注的 <strong>Event Labels</strong>，能直接“教会”模型识别这些高层语义特征。相比之下，无监督学习（如传统的聚类或掩码建模）可能只会让模型学会识别“草坪是绿色的”或“球员在跑动”，而难以自发理解“这是一个越位”这种复杂的逻辑关系。</li></ul><h3 id="2-预训练目标的互补性">2. 预训练目标的互补性</h3><p>根据文本，MatchVision 并不是只用监督学习，而是采用了<strong>混合策略</strong>：</p><ul><li><strong>监督分类 ($\mathcal{L}_{sup}$)</strong>：负责建立<strong>视觉特征与官方动作标签</strong>的强关联。</li><li><strong>对比学习 ($\mathcal{L}_{contra}$)</strong>：这其实具有一定的“弱监督”或“自监督”性质，它通过**视频与解说词（Textual Commentaries）**的匹配，让模型学习更丰富的语言描述能力。</li><li><strong>结合效果：</strong> 监督分类提供了“硬准则”（这是什么动作），而对比学习提供了“软语义”（这个动作怎么描述）。</li></ul><h3 id="3-提升特征的判别力-Discriminative-Power">3. 提升特征的判别力 (Discriminative Power)</h3><ul><li><strong>类内与类间差异：</strong> 足球视频中，很多动作看起来极其相似（例如，普通的传球和助攻传球在视觉上可能只有微小区别）。</li><li><strong>监督的作用：</strong> 使用交叉熵损失（Cross-Entropy Loss）的监督训练，会强制模型在特征空间中拉开不同事件类别的距离，从而在下游任务（如犯规识别）中表现得更精准。</li></ul><h3 id="4-行业数据集的现状">4. 行业数据集的现状</h3><ul><li><strong>标注资源：</strong> 足球领域拥有如 SoccerNet 这样大规模且高质量的标注数据集。</li><li><strong>效率考量：</strong> 既然已经有了现成的“正确答案（Labels）”，直接使用监督学习进行预训练，比让模型在海量无标注视频中漫无目的地探索（无监督）要高效得多。</li></ul><h4 id="什么是cls和cmt">什么是cls和cmt</h4><h2 id="1-CLS-Event-Classification-事件分类">1. CLS (Event Classification - 事件分类)</h2><p><strong>CLS</strong> 是 <strong>Classification</strong> 的缩写，主要负责“看图识事”，即识别视频中发生了什么特定事件。</p><ul><li><strong>核心功能：</strong> 将输入的足球视频片段归类为预定义的事件标签，例如“进球”、“角球”、“黄牌”或“换人”。</li><li><strong>实现机制：</strong> * 模型会引入一个可学习的 <strong>[cls] token</strong>，通过<strong>时间自注意力机制</strong>（Temporal Self-attention）汇总整段视频的时空特征。<ul><li>该特征随后被送入一个<strong>线性分类器</strong>（Linear Classifier）进行处理。</li></ul></li><li><strong>输出结果：</strong> 给出各个事件类别的概率分布，通常选取概率最高的一个作为最终判定结果（如：Type: “Yellow card”）。</li></ul><hr><h2 id="2-CMT-Commentary-Generation-解说生成">2. CMT (Commentary Generation - 解说生成)</h2><p><strong>CMT</strong> 是 <strong>Commentary</strong> 的缩写，主要负责“见图说话”，即生成像专业解说员一样的自然语言描述。</p><ul><li><strong>核心功能：</strong> 自动为视频片段编写一段符合赛况的叙述性文字。</li><li><strong>实现机制：</strong><ul><li>使用 <strong>Perceiver 聚合器</strong> 将复杂的视觉特征浓缩，并通过 <strong>MLP</strong> 映射为<strong>前缀嵌入</strong>（Prefix Embeddings）。</li><li>这些视觉嵌入被输入到**大语言模型（LLM）**中，引导 LLM 根据画面内容生成文本。</li></ul></li><li><strong>输出结果：</strong> 一段完整的句子，例如：“[REFEREE] shows a yellow card to [PLAYER]…”。</li></ul><h3 id="下游任务层">下游任务层</h3><p>预训练完成后，视觉编码器被“冻结”或作为骨干网络，通过不同的<strong>预测头 ($\Psi$)</strong> 来适配具体任务：</p><h3 id="事件分类-Psi-cls"><strong>事件分类 ($\Psi_{cls}$)</strong></h3><ul><li><strong>机制：</strong> 结构与预训练的监督学习类似，使用时间自注意力聚合特征。</li><li><strong>训练逻辑：</strong> 在<strong>冻结视觉编码器</strong>的情况下，仅训练线性分类器。</li><li><strong>输出：</strong> 给出视频属于哪种事件（如：角球、黄牌）的概率分布。</li></ul><h3 id="解说生成-Psi-Cmt"><strong>解说生成 ($\Psi_{Cmt}$)</strong></h3><ul><li><p><strong>核心组件：</strong> <strong>Perceiver 聚合器</strong> + <strong>MLP</strong> + <strong>LLM（大语言模型）</strong>。</p></li><li><p>流程： 1. Perceiver 将海量的视觉特征压缩。</p><p>\2. MLP 将其映射为 LLM 能听懂的“前缀嵌入（Prefix Embeddings）”。</p><p>\3. LLM 根据这些“视觉前缀”像写作文一样生成解说词。</p></li><li><p><strong>损失函数：</strong> 使用负对数似然损失（Next-Token Prediction）。</p></li></ul><h3 id="犯规识别-Psi-Foul"><strong>犯规识别 ($\Psi_{Foul}$)</strong></h3><ul><li><strong>输入：</strong> 足球比赛中常见的**多视角（Multi-view）**视频。</li><li><strong>处理：</strong> 使用池化技术（Max/Avg Pooling）将多视角特征整合为一个向量。</li><li><strong>双任务输出：</strong> 使用一个共享的 MLP 接两个分类器，同时预测：<ol><li><strong>犯规类型</strong>（如：铲球犯规、手球等，共 8 种）。</li><li><strong>严重程度</strong>（如：口头警告、黄牌、红牌等，共 4 级）。</li></ol></li></ul><p><strong>为什么要使用MLP</strong></p><p>实现跨模态的特征对齐，不需要更强大的模型，简单的MLP足够胜任模态对齐工作</p><h3 id="实验部分">实验部分</h3><p>基于他上面自己的soccer Replay 1988数据集进行实验</p><p>MatchVision在分类这个任务是达到了**82.5%**的准确率</p><p>证明对比学习比监督学习的效果更好</p><p>并且MatchVision在foul recongition方面，即使冻结了视觉编码器，也和顶尖模型不相上下</p><h3 id="最后部分">最后部分</h3><p>使用了LoRA技术调教LLM</p><p>这篇论文有三个比较大的贡献</p><p><strong>新资源</strong>：造出了迄今为止最大的足球数据集 <strong>SoccerReplay-1988</strong>。</p><p><strong>新模型</strong>：开发了专门针对足球时空特征的编码器 <strong>MatchVision</strong>。</p><p><strong>新标杆</strong>：在分类、解说、犯规识别等多个任务上都达到了<strong>世界领先水平 (SOTA)</strong>。</p><h2 id="Multi-Agent-System-for-Comprehensive-Soccer-Understanding">Multi-Agent System for Comprehensive Soccer Understanding</h2><h3 id="引言">引言</h3><p>论文在引言部分介绍了现在的研究在足球理解研究的一些挑战</p><p>在推理任务上比较的局限（局限于视觉分析而缺少了推理）</p><p>以及模型过于的碎片化和专家化</p><p><strong>这篇文章主要有四个贡献</strong></p><p><strong>构建了 SoccerWiki 知识库</strong>：这是第一个大规模的多模态足球知识库，集成了关于球员、球队、裁判和场地的丰富领域知识，旨在支持知识驱动的推理任务 。该库包含 9,471 名球员、266 支球队、202 名裁判和 235 个场地的详细信息 。</p><p><strong>建立了 SoccerBench 基准测试集</strong>：这是目前最大且最全面的足球领域专项基准 。它通过自动化的数据策划和人工验证构建，包含约 1 万个多模态（文本、图像、视频）选择题对，涵盖了背景知识、比赛局势识别、犯规识别等 13 项不同的足球分析任务 。</p><p><strong>开发了 SoccerAgent 多智能体系统</strong>：这是一种新型的多智能体协作系统，通过将复杂的足球问题分解为多个可执行的子任务来解决问题 。它利用了 SoccerWiki 的领域专家知识，并能够调用 18 个专项工具进行协作推理 。</p><p><strong>进行了广泛的评估与对比</strong>：作者在 SoccerBench 上将 SoccerAgent 与 11 种代表性的多模态大语言模型（MLLMs，如 GPT-4o、Claude 3.7、Gemini 2.0 等）进行了深入对比 。评估结果突显了该智能体系统在处理复杂、知识密集型足球任务中的优越性 。101</p><h3 id="介绍soccerBench">介绍soccerBench</h3><table><thead><tr><th><strong>维度</strong></th><th><strong>包含任务 (Index)</strong></th><th><strong>考查重点</strong></th></tr></thead><tbody><tr><td><strong>纯文本推理</strong> (TextQA)</td><td><strong>Q1</strong> 背景知识, <strong>Q2</strong> 比赛局势</td><td>考查模型是否掌握了球员历史、转会、比赛战术等“足球常识”。</td></tr><tr><td><strong>图像视觉感知</strong> (ImageQA)</td><td><strong>Q3</strong> 相机状态分类, <strong>Q4</strong> 图片背景知识, <strong>Q5</strong> 球衣号码识别, <strong>Q6</strong> 比分与时间识别</td><td>考查模型对单张转播截图的解析力，例如识别“这是哪场比赛”、“这是几号球员”。</td></tr><tr><td><strong>视频动态分析</strong> (VideoQA)</td><td><strong>Q7</strong> 相机切换, <strong>Q8</strong> 回放定位, <strong>Q9</strong> 动作分类, <strong>Q10/Q11</strong> 评论生成与理解, <strong>Q12</strong> 球衣颜色识别, <strong>Q13</strong> 多视角犯规识别</td><td><strong>最难的部分</strong>。考查模型能否理解动作的连贯性，并根据规则做出裁判级别的判断（如 Q13 判定是否犯规）。</td></tr></tbody></table><h3 id="研究动机">研究动机</h3><p>作者认为目前足球AI时效性不足，评价碎片化</p><p>作者构建了SoccerWIKI，并且在此基础上构建了SoccerBench</p><h4 id="Data-Curation">Data Curation</h4><p>团队采用不同的策略生成原始问答对（模版生成，大模型生成）</p><p>并且转化成四选一的选择题</p><p>最后通过自动化合成再经过人工筛选，组成了<strong>SoccerBench</strong></p><h3 id="SoccerAgent">SoccerAgent</h3><p><img src="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/image-20251225220605344.png" alt="SoccerAgent架构图"></p><p>论文的核心部分</p><h4 id="基于DeepSeek-V3的主模块协同工作">基于DeepSeek-V3的主模块协同工作</h4><p><strong>规划者 ($\mathcal{A}_{plan}$)</strong>：负责“思考”。它接收问题后，并不直接回答，而是分析需要哪些步骤，从工具包里挑选出最合适的<strong>工具链</strong>。</p><p><strong>执行者 ($\mathcal{A}_{exec}$)</strong>：负责“动手”。它按照规划好的顺序，一个接一个地运行工具。每一步都会参考之前的执行历史（$\mathcal{H}_{i}$），从而实现上下文感知的自适应调整。</p><h4 id="ToolBox">ToolBox</h4><p><strong>12 个足球专项工具</strong>：</p><p><strong>基础分析</strong>：动作分类器、评论生成 。</p><p><strong>检索专家</strong>：比赛搜索、比赛历史/信息检索、<strong>人脸识别</strong>（从 SoccerWiki 匹配球员） 。</p><p><strong>感知专家</strong>：相机状态检测、<strong>球衣号码/颜色识别</strong>、比分和时间识别 。</p><p><strong>高级裁判</strong>：<strong>犯规识别</strong>（通过多视角投票机制模拟 VAR）和回放定位 。</p><p><strong>6 个通用解析工具</strong>：</p><p>包括<strong>帧选择</strong>（将视频转为关键帧）、语义分割（定位特定物体）、实体搜索和文本检索等 。</p><h3 id="实验部分-2">实验部分</h3><p>比较重点的：我认为是容错能力</p><p><strong>自主调整：</strong> 执行者 ($\mathcal{A}_{exec}$) 在发现第一步失败后，并没有卡死，而是根据历史上下文自主调整策略，改用“比赛搜索”工具成功找回了所需信息 。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;报告人:王子通 | 2025/12/25&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;MatchTime 系列论文深度笔记&lt;/h1&gt;
&lt;h1&gt;第一篇论文 MatchTime: Towards Automatic Soccer Game Commentary Gener</summary>
      
    
    
    
    <category term="学术研究" scheme="https://jiyexingzou.github.io/categories/%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6/"/>
    
    
    <category term="论文笔记" scheme="https://jiyexingzou.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MatchTime" scheme="https://jiyexingzou.github.io/tags/MatchTime/"/>
    
    <category term="SoccerNet" scheme="https://jiyexingzou.github.io/tags/SoccerNet/"/>
    
    <category term="足球AI" scheme="https://jiyexingzou.github.io/tags/%E8%B6%B3%E7%90%83AI/"/>
    
  </entry>
  
  <entry>
    <title>别再说 AI 不懂球：MatchTime 系列论文深度笔记</title>
    <link href="https://jiyexingzou.github.io/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://jiyexingzou.github.io/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2025-12-23T11:49:29.000Z</published>
    <updated>2025-12-31T14:24:04.873Z</updated>
    
    <content type="html"><![CDATA[<h1>别再说 AI 不懂球：MatchTime 系列论文深度笔记（一）</h1><h2 id="核心痛点：消失的“16秒”">核心痛点：消失的“16秒”</h2><p>在足球视频领域，传统的解说词数据存在严重的<strong>音画不同步</strong>。由于原始数据大多抓取自实时文字直播，解说词往往比实际进球画面晚了 <strong>16.63 秒</strong>甚至更多。如果直接用这种“脏数据”训练，AI 只会学会“马后炮”。</p><hr><h2 id="第一章：数据治本——如何通过数学实现“降维打击”">第一章：数据治本——如何通过数学实现“降维打击”</h2><p>论文的核心贡献在于 <strong>Section 3.2 (Temporal Alignment Pipeline)</strong>，它展示了如何用一套自动化的管线将滞后的文本“拽”回正确的帧。</p><h3 id="1-亲和力矩阵-Affinity-Matrix-：连连看的底牌">1. 亲和力矩阵 (Affinity Matrix)：连连看的底牌</h3><p>为了对齐视频帧（Visual Frames）和解说词（Text Captions），作者引入了 <strong>Affinity Matrix  $\mathbb{A}$</strong>。</p><ul><li><strong>它是怎么来的？</strong> 假设视频有$n$ 帧，文本有 $k$ 句，矩阵的大小就是$k \times n$ 。</li></ul><h3 id="核心公式推导：亲和力矩阵-Affinity-Matrix">核心公式推导：亲和力矩阵 (Affinity Matrix)</h3><p>在计算视频帧 $V_j$ 与文本 $C_i$ 的相似度时，公式表达为：</p><p>$$\mathbb{A}[i, j] = \frac{C_i \cdot V_j^T}{||C_i|| \cdot ||V_j|| \cdot \tau}$$</p><p><strong>公式拆解：</strong></p><ul><li><strong>分子 ($C_i \cdot V_j^T$)</strong>：特征向量的点积，衡量方向一致性。</li><li><strong>分母 ($||C_i|| \cdot ||V_j||$)</strong>：$L_2$ 范数归一化，确保计算的是<strong>余弦相似度</strong>。</li><li><strong>$\tau$</strong>：温度参数，用来控制相似度分布的平滑度。</li><li><strong>深度解析</strong>：</li><li>** 是什么？** 这是向量的 ** 范数**（模长）。之所以要除以它，是为了进行<strong>归一化</strong>，将计算锁定为<strong>余弦相似度</strong>。我们只关心文本和画面的“语义方向”是否一致，而不关心特征向量本身的绝对大小。</li><li><strong>为什么要算这个？</strong> 通过寻找矩阵每一行中的最大值（），模型能自动锁死每一句解说词对应的“高光时刻”。</li></ul><hr><h2 id="第二章：模型架构——MatchVoice-的“翻译”逻辑">第二章：模型架构——MatchVoice 的“翻译”逻辑</h2><p>MatchVoice 的本质是一个<strong>多模态大模型 (MLLM)</strong>。它通过一套精密设计的组件，将视频“翻译”成文字。</p><h3 id="1-为什么视觉编码器-Visual-Encoder-要冻结？">1. 为什么视觉编码器 (Visual Encoder) 要冻结？</h3><p>在架构图中，你会看到视觉部分（如 CLIP 或 Baidu 特征）被打上了“雪花”图标（Frozen）。</p><ul><li><strong>策略</strong>：冻结预训练好的编码器可以保持其强大的通用特征提取能力，同时大幅降低训练成本。</li></ul><h3 id="2-Learnable-Queries-Attention：精准探测器">2. Learnable Queries &amp; Attention：精准探测器</h3><ul><li><strong>Learnable Queries</strong>：它们不是来自视频，而是模型内置的“探测员”。</li><li><strong>自注意力 (Self-Attention)</strong>：让这群“探测员”在出发前先开个会，分工合作（比如有的看人，有的看球）。</li><li><strong>交叉注意力 (Cross-Attention)</strong>：这是关键！探测员拿着清单去视频特征（超市货架）里取货，把散落在时空中的信息吸收到 Query 向量中。<br><img src="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/image-4.png" alt="alt text"></li></ul><h3 id="3-从投影到生成：MLP-与-Prefix-Tokens">3. 从投影到生成：MLP 与 Prefix Tokens</h3><ul><li><strong>MLP 的翻译官作用</strong>：视觉特征与 LLM 的维度往往不匹配。<strong>MLP (Projection Layer)</strong> 就像转换插头，将视觉特征投影到 LLM 能听懂的空间。</li><li><strong>Prefix Tokens (紫色方块)</strong>：这是 MLP 输出的唯一成果。它们作为“视觉前缀”喂给 LLM（如 LLaMA-3）。</li><li><strong>生成逻辑:$C = \Psi_{dec}(\Psi_{proj}(F))$。</strong>：。LLM 接收到视觉前缀后，开始顺着这个背景一个词一个词地吐出蓝色的 <strong>Commentary Tokens</strong>。</li></ul><hr><h2 id="第三章：评估的“金标准”——SN-Caption-test-align">第三章：评估的“金标准”——SN-Caption-test-align</h2><p>为了证明 AI 真的看懂了球，作者没有使用模糊的原始数据进行评估，而是打造了 <strong>SN-Caption-test-align</strong>。</p><ul><li><strong>本质</strong>：这是对 SoccerNet-Caption 的<strong>人工精修版</strong>。</li><li><strong>意义</strong>：它不仅是一个数据集，更是一个“公正的考官”。只有在时间戳绝对准确的考卷上拿到高分（如 <strong>CIDEr</strong> 分数的暴涨），才能证明对齐管线的有效性。</li></ul><hr><ul><li><strong>Baidu 特征最强</strong>：实验证明，相比通用的 CLIP，这种在足球领域“深造”过的模型（Baidu Soccer Embeddings）作为视觉编码器效果最佳。</li><li><strong>数据 &gt; 模型</strong>：即便使用基础的 ResNet，只要用了对齐后的 MatchTime 数据集，表现甚至能超越在脏数据上跑的高级模型。</li></ul><hr><h2 id="第二篇论文-Towards-Universal-Soccer-Video-Understanding">第二篇论文 Towards Universal Soccer Video Understanding</h2><p>第二篇论文在第一篇论文的基础上提出了SoccerReplay-1988数据集。<br>并且提出了足球专用的解码器MatchVison</p><h3 id="SoccerReplay-19886-Dataset">SoccerReplay-19886 Dataset</h3><p>这篇文章阐述了这个作者是如何做这个数据集的，将视频分为上下两场，从starting at kick off开始。并且采用第一篇文章的MatchTime的对齐方式，通过手动进行人工对齐</p><p><img src="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/image-5.png" alt="alt text"></p><h3 id="对于模型我自己的理解">对于模型我自己的理解:</h3><p>本质上就是一个改进的video transformer</p><h4 id="Token-Embedding">Token Embedding</h4><p><strong>空间切分：</strong> 每一帧图像 $ i $ 被切分成 $ M $ 个不重叠的小方块（Patches）。这就像把一张照片剪成方格阵列。</p><p><strong>线性映射 ($\Phi_{Emb}$)：</strong> 每个小方块被拉平并转换成一个维度为 $D$ 的向量。</p><p><strong>双重位置编码 (Position Embedding)：</strong> 这是关键。</p><ul><li><strong>空间位置编码 ($e_s^{pos}$)</strong>：告诉模型这个方块在画面的哪个位置（左上还是右下）。</li><li><strong>时间位置编码 ($e_t^{pos}$)</strong>：在处理完整个视频序列后叠加，告诉模型这一组特征属于视频的第几秒。</li></ul><p><strong>[CLS] 标记：</strong> 每一帧都会加入一个特殊的 <code>[cls]</code> 标记，专门用来汇总这一帧的全局信息。</p><h4 id="时空注意力模块">时空注意力模块</h4><p><strong>时间自注意力 ($\phi_t$)：</strong></p><ul><li><strong>操作：</strong> 只在不同帧的<strong>相同空间位置</strong>的 Token 之间进行计算。</li><li><strong>目的：</strong> 追踪动作。例如，第1帧里的足球在左边，第2帧里的足球移动到了中间，时间注意力负责捕捉这个“移动”轨迹。</li></ul><p><strong>空间自注意力 ($\phi_s$)：</strong></p><ul><li><strong>操作：</strong> 只在<strong>同一帧内部</strong>的不同 Token 之间进行计算。</li><li><strong>目的：</strong> 理解布局。例如，识别出这一帧画面里哪是球员、哪是球门、哪是裁判。</li></ul><p><strong>交替堆叠 ($K$ 次)：</strong> 通过多次交替循环，模型既能看清每一帧的细节，又能理解动作在时间上的逻辑。</p><h4 id="聚合层-Aggregation-Layer">聚合层(Aggregation Layer)</h4><p>在经过复杂的注意力计算后，模型需要把海量的数据“浓缩”成一个简洁的特征向量，供下游任务使用。</p><ul><li><strong>空间聚合：</strong> 利用聚合层 $\Phi_{Agg}$，将每一帧中散落在各个 Patch 里的信息，全部压缩到该帧的 <code>[cls]</code> 标记中（得到 $\hat{F}_i^{CLS}$）。</li><li><strong>最终表示 ($F_V$)：</strong> 将所有帧的 <code>[cls]</code> 标记拼接起来。<ul><li><strong>结果：</strong> 得到的 $F_V$ 是一个矩阵，它每一行代表一帧的精华，整组矩阵代表了整个视频片段的精华。</li></ul></li></ul><h3 id="预训练层">预训练层</h3><h3 id="监督分类-Supervised-Classification-mathcal-L-sup"><strong>监督分类 (Supervised Classification, $\mathcal{L}_{sup}$)</strong></h3><ul><li><strong>做法：</strong> 将提取出的视频特征 $F_V$ 通过一个<strong>时间自注意力层</strong>，汇总到一个可学习的 <code>[cls]</code> 标记中。</li><li><strong>计算：</strong> 这个标记被输入线性分类器，使用<strong>交叉熵损失 (Cross-Entropy Loss)</strong> 进行训练。</li><li><strong>目的：</strong> 让模型学会“看图识事”，即直接根据画面判断这是进球还是犯规。</li></ul><h3 id="视频-语言对比学习-Video-Language-Contrastive-Learning-mathcal-L-contra"><strong>视频-语言对比学习 (Video-Language Contrastive Learning, $\mathcal{L}_{contra}$)</strong></h3><ul><li><strong>做法：</strong> 对视频特征进行平均池化得到 $F_V^{Avg}$，同时用文本编码器处理解说词 $C$。</li><li><strong>创新点：</strong> 借鉴了 <strong>SigLIP</strong> 的损失函数。</li><li><strong>正样本优化：</strong> 针对足球比赛中经常出现高度相似的解说（如“比赛开始”），模型将同一批次中相似度高的文本都视为正样本，增强了鲁棒性。</li><li><strong>目的：</strong> 建立视觉与文本的语义联系，为下游的解说生成任务打好基础。</li></ul><h3 id="疑问：">疑问：</h3><h4 id="为什么是监督分类？">为什么是监督分类？</h4><h3 id="1-足球语义的复杂性与明确性">1. 足球语义的复杂性与明确性</h3><ul><li><strong>语义明确：</strong> 足球比赛中的关键事件（如进球、黄牌、换人）都有非常明确的官方定义和边界。</li><li><strong>监督优势：</strong> 监督分类通过使用专家标注的 <strong>Event Labels</strong>，能直接“教会”模型识别这些高层语义特征。相比之下，无监督学习（如传统的聚类或掩码建模）可能只会让模型学会识别“草坪是绿色的”或“球员在跑动”，而难以自发理解“这是一个越位”这种复杂的逻辑关系。</li></ul><h3 id="2-预训练目标的互补性">2. 预训练目标的互补性</h3><p>根据文本，MatchVision 并不是只用监督学习，而是采用了<strong>混合策略</strong>：</p><ul><li><strong>监督分类 ($\mathcal{L}_{sup}$)</strong>：负责建立<strong>视觉特征与官方动作标签</strong>的强关联。</li><li><strong>对比学习 ($\mathcal{L}_{contra}$)</strong>：这其实具有一定的“弱监督”或“自监督”性质，它通过**视频与解说词（Textual Commentaries）**的匹配，让模型学习更丰富的语言描述能力。</li><li><strong>结合效果：</strong> 监督分类提供了“硬准则”（这是什么动作），而对比学习提供了“软语义”（这个动作怎么描述）。</li></ul><h3 id="3-提升特征的判别力-Discriminative-Power">3. 提升特征的判别力 (Discriminative Power)</h3><ul><li><strong>类内与类间差异：</strong> 足球视频中，很多动作看起来极其相似（例如，普通的传球和助攻传球在视觉上可能只有微小区别）。</li><li><strong>监督的作用：</strong> 使用交叉熵损失（Cross-Entropy Loss）的监督训练，会强制模型在特征空间中拉开不同事件类别的距离，从而在下游任务（如犯规识别）中表现得更精准。</li></ul><h3 id="4-行业数据集的现状">4. 行业数据集的现状</h3><ul><li><strong>标注资源：</strong> 足球领域拥有如 SoccerNet 这样大规模且高质量的标注数据集。</li><li><strong>效率考量：</strong> 既然已经有了现成的“正确答案（Labels）”，直接使用监督学习进行预训练，比让模型在海量无标注视频中漫无目的地探索（无监督）要高效得多。</li></ul><h4 id="什么是cls和cmt">什么是cls和cmt</h4><h2 id="1-CLS-Event-Classification-事件分类">1. CLS (Event Classification - 事件分类)</h2><p><strong>CLS</strong> 是 <strong>Classification</strong> 的缩写，主要负责“看图识事”，即识别视频中发生了什么特定事件。</p><ul><li><strong>核心功能：</strong> 将输入的足球视频片段归类为预定义的事件标签，例如“进球”、“角球”、“黄牌”或“换人”。</li><li><strong>实现机制：</strong> * 模型会引入一个可学习的 <strong>[cls] token</strong>，通过<strong>时间自注意力机制</strong>（Temporal Self-attention）汇总整段视频的时空特征。<ul><li>该特征随后被送入一个<strong>线性分类器</strong>（Linear Classifier）进行处理。</li></ul></li><li><strong>输出结果：</strong> 给出各个事件类别的概率分布，通常选取概率最高的一个作为最终判定结果（如：Type: “Yellow card”）。</li></ul><hr><h2 id="2-CMT-Commentary-Generation-解说生成">2. CMT (Commentary Generation - 解说生成)</h2><p><strong>CMT</strong> 是 <strong>Commentary</strong> 的缩写，主要负责“见图说话”，即生成像专业解说员一样的自然语言描述。</p><ul><li><strong>核心功能：</strong> 自动为视频片段编写一段符合赛况的叙述性文字。</li><li><strong>实现机制：</strong><ul><li>使用 <strong>Perceiver 聚合器</strong> 将复杂的视觉特征浓缩，并通过 <strong>MLP</strong> 映射为<strong>前缀嵌入</strong>（Prefix Embeddings）。</li><li>这些视觉嵌入被输入到**大语言模型（LLM）**中，引导 LLM 根据画面内容生成文本。</li></ul></li><li><strong>输出结果：</strong> 一段完整的句子，例如：“[REFEREE] shows a yellow card to [PLAYER]…”。</li></ul><h3 id="下游任务层">下游任务层</h3><p>预训练完成后，视觉编码器被“冻结”或作为骨干网络，通过不同的<strong>预测头 ($\Psi$)</strong> 来适配具体任务：</p><h3 id="事件分类-Psi-cls"><strong>事件分类 ($\Psi_{cls}$)</strong></h3><ul><li><strong>机制：</strong> 结构与预训练的监督学习类似，使用时间自注意力聚合特征。</li><li><strong>训练逻辑：</strong> 在<strong>冻结视觉编码器</strong>的情况下，仅训练线性分类器。</li><li><strong>输出：</strong> 给出视频属于哪种事件（如：角球、黄牌）的概率分布。</li></ul><h3 id="解说生成-Psi-Cmt"><strong>解说生成 ($\Psi_{Cmt}$)</strong></h3><ul><li><p><strong>核心组件：</strong> <strong>Perceiver 聚合器</strong> + <strong>MLP</strong> + <strong>LLM（大语言模型）</strong>。</p></li><li><p>流程： 1. Perceiver 将海量的视觉特征压缩。</p><p>\2. MLP 将其映射为 LLM 能听懂的“前缀嵌入（Prefix Embeddings）”。</p><p>\3. LLM 根据这些“视觉前缀”像写作文一样生成解说词。</p></li><li><p><strong>损失函数：</strong> 使用负对数似然损失（Next-Token Prediction）。</p></li></ul><h3 id="犯规识别-Psi-Foul"><strong>犯规识别 ($\Psi_{Foul}$)</strong></h3><ul><li><strong>输入：</strong> 足球比赛中常见的**多视角（Multi-view）**视频。</li><li><strong>处理：</strong> 使用池化技术（Max/Avg Pooling）将多视角特征整合为一个向量。</li><li><strong>双任务输出：</strong> 使用一个共享的 MLP 接两个分类器，同时预测：<ol><li><strong>犯规类型</strong>（如：铲球犯规、手球等，共 8 种）。</li><li><strong>严重程度</strong>（如：口头警告、黄牌、红牌等，共 4 级）。</li></ol></li></ul><p><strong>为什么要使用MLP</strong></p><p>实现跨模态的特征对齐，不需要更强大的模型，简单的MLP足够胜任模态对齐工作</p><h3 id="实验部分">实验部分</h3><p>基于他上面自己的soccer Replay 1988数据集进行实验</p><p>MatchVision在分类这个任务是达到了**82.5%**的准确率</p><p>证明对比学习比监督学习的效果更好</p><p>并且MatchVision在foul recongition方面，即使冻结了视觉编码器，也和顶尖模型不相上下</p><h3 id="最后部分">最后部分</h3><p>使用了LoRA技术调教LLM</p><p>这篇论文有三个比较大的贡献</p><p><strong>新资源</strong>：造出了迄今为止最大的足球数据集 <strong>SoccerReplay-1988</strong>。</p><p><strong>新模型</strong>：开发了专门针对足球时空特征的编码器 <strong>MatchVision</strong>。</p><p><strong>新标杆</strong>：在分类、解说、犯规识别等多个任务上都达到了<strong>世界领先水平 (SOTA)</strong>。</p><h2 id="Multi-Agent-System-for-Comprehensive-Soccer-Understanding">Multi-Agent System for Comprehensive Soccer Understanding</h2><h3 id="引言">引言</h3><p>论文在引言部分介绍了现在的研究在足球理解研究的一些挑战</p><p>在推理任务上比较的局限（局限于视觉分析而缺少了推理）</p><p>以及模型过于的碎片化和专家化</p><p><strong>这篇文章主要有四个贡献</strong></p><p><strong>构建了 SoccerWiki 知识库</strong>：这是第一个大规模的多模态足球知识库，集成了关于球员、球队、裁判和场地的丰富领域知识，旨在支持知识驱动的推理任务 。该库包含 9,471 名球员、266 支球队、202 名裁判和 235 个场地的详细信息 。</p><p><strong>建立了 SoccerBench 基准测试集</strong>：这是目前最大且最全面的足球领域专项基准 。它通过自动化的数据策划和人工验证构建，包含约 1 万个多模态（文本、图像、视频）选择题对，涵盖了背景知识、比赛局势识别、犯规识别等 13 项不同的足球分析任务 。</p><p><strong>开发了 SoccerAgent 多智能体系统</strong>：这是一种新型的多智能体协作系统，通过将复杂的足球问题分解为多个可执行的子任务来解决问题 。它利用了 SoccerWiki 的领域专家知识，并能够调用 18 个专项工具进行协作推理 。</p><p><strong>进行了广泛的评估与对比</strong>：作者在 SoccerBench 上将 SoccerAgent 与 11 种代表性的多模态大语言模型（MLLMs，如 GPT-4o、Claude 3.7、Gemini 2.0 等）进行了深入对比 。评估结果突显了该智能体系统在处理复杂、知识密集型足球任务中的优越性 。101</p><h3 id="介绍soccerBench">介绍soccerBench</h3><table><thead><tr><th><strong>维度</strong></th><th><strong>包含任务 (Index)</strong></th><th><strong>考查重点</strong></th></tr></thead><tbody><tr><td><strong>纯文本推理</strong> (TextQA)</td><td><strong>Q1</strong> 背景知识, <strong>Q2</strong> 比赛局势</td><td>考查模型是否掌握了球员历史、转会、比赛战术等“足球常识”。</td></tr><tr><td><strong>图像视觉感知</strong> (ImageQA)</td><td><strong>Q3</strong> 相机状态分类, <strong>Q4</strong> 图片背景知识, <strong>Q5</strong> 球衣号码识别, <strong>Q6</strong> 比分与时间识别</td><td>考查模型对单张转播截图的解析力，例如识别“这是哪场比赛”、“这是几号球员”。</td></tr><tr><td><strong>视频动态分析</strong> (VideoQA)</td><td><strong>Q7</strong> 相机切换, <strong>Q8</strong> 回放定位, <strong>Q9</strong> 动作分类, <strong>Q10/Q11</strong> 评论生成与理解, <strong>Q12</strong> 球衣颜色识别, <strong>Q13</strong> 多视角犯规识别</td><td><strong>最难的部分</strong>。考查模型能否理解动作的连贯性，并根据规则做出裁判级别的判断（如 Q13 判定是否犯规）。</td></tr></tbody></table><h3 id="研究动机">研究动机</h3><p>作者认为目前足球AI时效性不足，评价碎片化</p><p>作者构建了SoccerWIKI，并且在此基础上构建了SoccerBench</p><h4 id="Data-Curation">Data Curation</h4><p>团队采用不同的策略生成原始问答对（模版生成，大模型生成）</p><p>并且转化成四选一的选择题</p><p>最后通过自动化合成再经过人工筛选，组成了<strong>SoccerBench</strong></p><h3 id="SoccerAgent">SoccerAgent</h3><p>论文的核心部分</p><h4 id="基于DeepSeek-V3的主模块协同工作">基于DeepSeek-V3的主模块协同工作</h4><p><strong>规划者 ($\mathcal{A}_{plan}$)</strong>：负责“思考”。它接收问题后，并不直接回答，而是分析需要哪些步骤，从工具包里挑选出最合适的<strong>工具链</strong>。</p><p><strong>执行者 ($\mathcal{A}_{exec}$)</strong>：负责“动手”。它按照规划好的顺序，一个接一个地运行工具。每一步都会参考之前的执行历史（$\mathcal{H}_{i}$），从而实现上下文感知的自适应调整。</p><h4 id="ToolBox">ToolBox</h4><p><strong>12 个足球专项工具</strong>：</p><p><strong>基础分析</strong>：动作分类器、评论生成 。</p><p><strong>检索专家</strong>：比赛搜索、比赛历史/信息检索、<strong>人脸识别</strong>（从 SoccerWiki 匹配球员） 。</p><p><strong>感知专家</strong>：相机状态检测、<strong>球衣号码/颜色识别</strong>、比分和时间识别 。</p><p><strong>高级裁判</strong>：<strong>犯规识别</strong>（通过多视角投票机制模拟 VAR）和回放定位 。</p><p><strong>6 个通用解析工具</strong>：</p><p>包括<strong>帧选择</strong>（将视频转为关键帧）、语义分割（定位特定物体）、实体搜索和文本检索等 。</p><h3 id="实验部分-2">实验部分</h3><p>比较重点的：我认为是容错能力</p><p><strong>自主调整：</strong> 执行者 ($\mathcal{A}_{exec}$) 在发现第一步失败后，并没有卡死，而是根据历史上下文自主调整策略，改用“比赛搜索”工具成功找回了所需信息 。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;别再说 AI 不懂球：MatchTime 系列论文深度笔记（一）&lt;/h1&gt;
&lt;h2 id=&quot;核心痛点：消失的“16秒”&quot;&gt;核心痛点：消失的“16秒”&lt;/h2&gt;
&lt;p&gt;在足球视频领域，传统的解说词数据存在严重的&lt;strong&gt;音画不同步&lt;/strong&gt;。由于原始数据大多抓</summary>
      
    
    
    
    <category term="学术研究" scheme="https://jiyexingzou.github.io/categories/%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6/"/>
    
    
    <category term="论文笔记" scheme="https://jiyexingzou.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MatchTime" scheme="https://jiyexingzou.github.io/tags/MatchTime/"/>
    
    <category term="SoccerNet" scheme="https://jiyexingzou.github.io/tags/SoccerNet/"/>
    
    <category term="足球AI" scheme="https://jiyexingzou.github.io/tags/%E8%B6%B3%E7%90%83AI/"/>
    
  </entry>
  
  <entry>
    <title>样式迁移</title>
    <link href="https://jiyexingzou.github.io/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/"/>
    <id>https://jiyexingzou.github.io/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/</id>
    <published>2025-11-20T13:20:41.000Z</published>
    <updated>2025-12-31T14:16:02.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>样式迁移：将一个图片的风格样式转移到另一个图片上</p><p>最早的样式迁移：基于CNN的样式迁移<br>基于CNN的样式迁移<br><img src="/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/image-4.png" alt="alt text"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;样式迁移：将一个图片的风格样式转移到另一个图片上&lt;/p&gt;
&lt;p&gt;最早的样式迁移：基于CNN的样式迁移&lt;br&gt;
基于CNN的样式迁移&lt;br&gt;
&lt;img src=&quot;/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://jiyexingzou.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="样式迁移" scheme="https://jiyexingzou.github.io/tags/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/"/>
    
  </entry>
  
  <entry>
    <title>科研实习寻找经验</title>
    <link href="https://jiyexingzou.github.io/2025/11/11/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%AF%BB%E6%89%BE%E7%BB%8F%E9%AA%8C/"/>
    <id>https://jiyexingzou.github.io/2025/11/11/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%AF%BB%E6%89%BE%E7%BB%8F%E9%AA%8C/</id>
    <published>2025-11-11T07:14:15.000Z</published>
    <updated>2025-12-31T14:16:00.338Z</updated>
    
    <content type="html"><![CDATA[<h2 id="USTC-张少峰老师">USTC 张少峰老师</h2><p>投递的USTC人工智能与大数据实验室，张少峰老师，未被回复</p><h1>10 月 28 日</h1><p>再度投递，依旧未回复</p><h1>11 月 11 日</h1><p>找到的招科研实习的老师</p><h2 id="SJTU-张林峰-老师">SJTU 张林峰 老师</h2><p>研究方向:Efficient AI<br>招聘界面:<br><a href="https://zhuanlan.zhihu.com/p/1910049209664660559">https://zhuanlan.zhihu.com/p/1910049209664660559</a><br>实验室主页:<br>www.zhanglinfeng.tech<br>老师邮箱:zhanglinfeng@sjtu.edu.cn</p><h2 id="NJU-刘佳恒老师">NJU 刘佳恒老师</h2><p>南京大学-大规模智能与知识实验室（NJU-LINK, Large-scale Intelligence and Knowledge Lab）<br>老师邮箱:211300096@smail.nju.edu.cn<br>招聘界面:<br><a href="https://www.nju-link.com/zh/post/25-7-21-recruit2/">https://www.nju-link.com/zh/post/25-7-21-recruit2/</a></p><h2 id="RUC-金琴老师">RUC 金琴老师</h2><p>投递邮箱:aim3.ruc@gmail.com<br>邮件中附上简历、兴趣方向和预期的实习时间等信息<br>实验室主页:<br><a href="https://www.ruc-aim3.com/">https://www.ruc-aim3.com/</a><br>招聘界面:<br><a href="https://zhuanlan.zhihu.com/p/1917932252114973992">https://zhuanlan.zhihu.com/p/1917932252114973992</a></p><h2 id="西湖大学-Westlake-university">西湖大学 Westlake university</h2><p>LINs Lab<br>实验室主页:<br><a href="https://lins-lab.github.io/">https://lins-lab.github.io/</a><br>招聘界面:<br><a href="https://zhuanlan.zhihu.com/p/690440155">https://zhuanlan.zhihu.com/p/690440155</a></p><h1>11 月 13日</h1><h2 id="NJU-范崎老师">NJU 范崎老师</h2><p>智能科学与技术学院<br>申请要求：</p><ol><li>热爱科研（最最重要！）</li><li>有一定的相关基础</li><li>在读本科生、硕士生、博士生均可。也欢迎已经毕业的朋友进行科研合作</li><li>线下线上均可</li></ol><p>联系方式：fanqi@nju.edu.cn<br>请附带简历和成绩单</p><h1>已经错过时间但是可以去了解的计划:</h1><h2 id="西湖大学-暑期研究计划">西湖大学 暑期研究计划</h2><h2 id="中国科学院大学-大学生创新实践训练集计划">中国科学院大学 大学生创新实践训练集计划</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;USTC-张少峰老师&quot;&gt;USTC 张少峰老师&lt;/h2&gt;
&lt;p&gt;投递的USTC人工智能与大数据实验室，张少峰老师，未被回复&lt;/p&gt;
&lt;h1&gt;10 月 28 日&lt;/h1&gt;
&lt;p&gt;再度投递，依旧未回复&lt;/p&gt;
&lt;h1&gt;11 月 11 日&lt;/h1&gt;
&lt;p&gt;找到的招科研实习</summary>
      
    
    
    
    
    <category term="科研" scheme="https://jiyexingzou.github.io/tags/%E7%A7%91%E7%A0%94/"/>
    
    <category term="实习" scheme="https://jiyexingzou.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
    <category term="经验" scheme="https://jiyexingzou.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络</title>
    <link href="https://jiyexingzou.github.io/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <id>https://jiyexingzou.github.io/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</id>
    <published>2025-05-09T08:57:20.000Z</published>
    <updated>2025-12-31T14:24:18.806Z</updated>
    
    <content type="html"><![CDATA[<h1>第一章</h1><h2 id="1-1">1.1</h2><h3 id="1-1-1-计算机网络的概念">1.1_1 计算机网络的概念</h3><p><strong>什么是计算机网络</strong><br>计算机网络是一个将众多分散的，自治的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。<br><strong>计算机网络vs互连网vs互联网</strong><br><strong>计算机网络</strong>:由若干结点和连接这些节点的链路组成的。<br>结点可以是:计算机，集线器，交换机，路由器。<br>链路可以是有线链路，无线链路。<br><strong>互连网</strong>:若干个计算机网络通过路由器连接起来的网络。<br>ISP：互联网服务提供商<br><strong>互联网</strong>：由多个互连网通过路由器连接起来的网络。<br><strong>TCP/IP协议：</strong><br>互联网必须用TCP/IP协议，而互连网则可以用不同的协议。</p><h3 id="1-1-2-计算机网络的组成和功能">1.1_2 计算机网络的组成和功能</h3><p>计算机网络的功能</p><h3 id="1-1-3-1-电路交换-报文交换-分组交换">1.1_3_1 电路交换 报文交换 分组交换</h3><p><strong>电路交换</strong>:通过物理线路的连接，动态的分配传输线路资源</p><p><strong>电路交换的优点：</strong><br>通信前从主叫端到被叫端建立一条专用的物理通路，在通信的全部时间内，两个用户始终占用端到端的线路资源。数据直送，传输速率高<br>电路交换更适用于：低频次、大量地传输数据<br><strong>电路交换的缺点：</strong><br>建立/释放连接，需长额外的时间开销</p><p><strong>报文交换:</strong></p><p><strong>报文交换的优点：</strong><br>·通信前无需建立连接<br>数据以“报文”为单位被交换节点间“存储转发”，通信线路可以灵活分配<br>在通信时间内，两个用户无需独占一整条物理线路。相比于电路交换，线路利用率高<br>交换节点支持“差错控制”（通过校验技术）<br><strong>报文交换的缺点：</strong><br>报文不定长，不方便存储转发管理<br>长报文的存储转发时间开销大、缓存开销大长报文容易出错，重传代价高</p><p>**分组交换:**将长报文的数据切成定长的数据</p><p><strong>分组交换的优点：</strong><br>通信前无需建立连接<br>数据以“分组”为单位被交换节点间“存储转发”，通信线路可以灵活分配<br>在通信时间内，两个用户无需独占一整条物理线路。相比于电路交换，线路利用率高<br>交换节点支持“差错控制”（通过校验技术)<br>相比于报文交换，分组交换改进了如下问题：<br>分组定长，方便存储转发管理<br>分组的存储转发时间开销小、缓存开销小<br>分组不易出错，重传代价低<br><strong>分组交换的缺点：</strong><br>相比于报文交换，控制信息占比增加<br>相比于电路交换，依然存在存储转发时延</p><p>虚电路交换</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;第一章&lt;/h1&gt;
&lt;h2 id=&quot;1-1&quot;&gt;1.1&lt;/h2&gt;
&lt;h3 id=&quot;1-1-1-计算机网络的概念&quot;&gt;1.1_1 计算机网络的概念&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;什么是计算机网络&lt;/strong&gt;&lt;br&gt;
计算机网络是一个将众多分散的，自治的计算机系统，通过通信</summary>
      
    
    
    
    
    <category term="学习笔记" scheme="https://jiyexingzou.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机网络" scheme="https://jiyexingzou.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>ResNet</title>
    <link href="https://jiyexingzou.github.io/2025/04/28/ResNet/"/>
    <id>https://jiyexingzou.github.io/2025/04/28/ResNet/</id>
    <published>2025-04-28T12:00:34.000Z</published>
    <updated>2025-12-31T14:15:55.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="核心思想">核心思想</h2><p>加更多层不会让你变差</p><h2 id="残差块">残差块</h2><p>f(x) = x + g(x)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;核心思想&quot;&gt;核心思想&lt;/h2&gt;
&lt;p&gt;加更多层不会让你变差&lt;/p&gt;
&lt;h2 id=&quot;残差块&quot;&gt;残差块&lt;/h2&gt;
&lt;p&gt;f(x) = x + g(x)&lt;/p&gt;
</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://jiyexingzou.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ResNet" scheme="https://jiyexingzou.github.io/tags/ResNet/"/>
    
    <category term="神经网络" scheme="https://jiyexingzou.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>批量归一化</title>
    <link href="https://jiyexingzou.github.io/2025/04/28/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <id>https://jiyexingzou.github.io/2025/04/28/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/</id>
    <published>2025-04-28T11:22:38.000Z</published>
    <updated>2025-12-31T14:15:53.314Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题分析">问题分析</h2><p>损失出现在最后，后面的层训练较快，数据在最底部。</p><p>底部的层训练较慢，底部层一变化，所有都得跟着变，最后的那些层需要重新学习多次，导致收敛变慢。<br>底部的层训练较慢<br>底部层一变化，所有都得跟着变<br>最后的那些层需要重新学习多次<br>导致收敛变慢</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题分析&quot;&gt;问题分析&lt;/h2&gt;
&lt;p&gt;损失出现在最后，后面的层训练较快，数据在最底部。&lt;/p&gt;
&lt;p&gt;底部的层训练较慢，底部层一变化，所有都得跟着变，最后的那些层需要重新学习多次，导致收敛变慢。&lt;br&gt;
底部的层训练较慢&lt;br&gt;
底部层一变化，所有都得跟着变&lt;br</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://jiyexingzou.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="批量归一化" scheme="https://jiyexingzou.github.io/tags/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>含并行连结的网络GoogLeNet</title>
    <link href="https://jiyexingzou.github.io/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/"/>
    <id>https://jiyexingzou.github.io/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/</id>
    <published>2025-04-28T10:43:11.000Z</published>
    <updated>2025-12-31T14:16:04.260Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GoogLeNet">GoogLeNet</h2><p>第一个可以做到超过100层的卷积神经网络，致敬LeNet</p><h3 id="Inception块">Inception块</h3><p>使用不同窗口大小的卷积层<br>致敬LeNet<br>Inception块:<br>使用不同窗口大小的卷积层<br><img src="/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/image-2.png" alt="alt text"></p><p>GoogLeNet<br><img src="/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/image-3.png" alt="alt text"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;GoogLeNet&quot;&gt;GoogLeNet&lt;/h2&gt;
&lt;p&gt;第一个可以做到超过100层的卷积神经网络，致敬LeNet&lt;/p&gt;
&lt;h3 id=&quot;Inception块&quot;&gt;Inception块&lt;/h3&gt;
&lt;p&gt;使用不同窗口大小的卷积层&lt;br&gt;
致敬LeNet&lt;br&gt;
In</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://jiyexingzou.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="神经网络" scheme="https://jiyexingzou.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="GoogLeNet" scheme="https://jiyexingzou.github.io/tags/GoogLeNet/"/>
    
  </entry>
  
  <entry>
    <title>网络中的网络NIN</title>
    <link href="https://jiyexingzou.github.io/2025/04/28/%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9CNIN/"/>
    <id>https://jiyexingzou.github.io/2025/04/28/%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9CNIN/</id>
    <published>2025-04-28T10:09:14.000Z</published>
    <updated>2025-12-31T14:15:51.614Z</updated>
    
    <content type="html"><![CDATA[<h2 id="NIN核心思想">NIN核心思想</h2><p>卷积层需要较少的参数，但卷积层后的第一个全连接层的参数很高。<br>参数的计算=输入的通道数x输出的通道数x高x宽<br>VGG占用的内存非常的大<br>NIN的思想就是，完全不要全连接层<br>MLP<br>一个卷积层加两个全连接层<br>整体架构:<br>无全连接层<br>交替使用NIN块和步幅为2的最大池化层<br>逐步减小高宽和增大通道数<br>最后使用全局平均池化层得到输出<br>其输入通道数是类别数</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;NIN核心思想&quot;&gt;NIN核心思想&lt;/h2&gt;
&lt;p&gt;卷积层需要较少的参数，但卷积层后的第一个全连接层的参数很高。&lt;br&gt;
参数的计算=输入的通道数x输出的通道数x高x宽&lt;br&gt;
VGG占用的内存非常的大&lt;br&gt;
NIN的思想就是，完全不要全连接层&lt;br&gt;
MLP&lt;b</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://jiyexingzou.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="神经网络" scheme="https://jiyexingzou.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="NIN" scheme="https://jiyexingzou.github.io/tags/NIN/"/>
    
  </entry>
  
  <entry>
    <title>使用块的网络VGG</title>
    <link href="https://jiyexingzou.github.io/2025/04/25/%E4%BD%BF%E7%94%A8%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9CVGG/"/>
    <id>https://jiyexingzou.github.io/2025/04/25/%E4%BD%BF%E7%94%A8%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9CVGG/</id>
    <published>2025-04-25T11:44:10.000Z</published>
    <updated>2025-12-31T14:15:36.924Z</updated>
    
    <content type="html"><![CDATA[<h2 id="VGG网络">VGG网络</h2><h3 id="核心思想">核心思想</h3><p>能不能更深更大获得更好的精度？<br>更多的全连接层<br>更多的卷积层<br>将卷积层组合成块<br><img src="/2025/04/25/%E4%BD%BF%E7%94%A8%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9CVGG/image.png" alt="alt text"><br>深但窄效果更好<br>多个VGG块后接全连接层<br>不同次数的重复块得到不同的架构<br>VGG-16，VGG-19<br>更大更深的AlexNet<br>非常的占内存</p><pre><code class="highlight python"><span class="keyword">import</span> torch<span class="keyword">from</span> torch <span class="keyword">import</span> nn<span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l<span class="comment"># VGG块的实现</span><span class="keyword">def</span> <span class="title function_">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):    layers = []    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):        layers.append(nn.Conv2d(in_channels, out_channels,                                kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))        layers.append(nn.ReLU())        in_channels = out_channels    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>))    <span class="keyword">return</span> nn.Sequential(*layers)</code></pre><pre><code class="highlight python">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>))    conv_blks = []    in_channels = <span class="number">1</span>    <span class="comment"># 卷积层部分</span>    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv_arch:        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))        in_channels = out_channels    <span class="keyword">return</span> nn.Sequential(        *conv_blks, nn.Flatten(),        <span class="comment"># 全连接层部分</span>        nn.Linear(out_channels * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),        nn.Linear(<span class="number">4096</span>, <span class="number">10</span>))net = vgg(conv_arch)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;VGG网络&quot;&gt;VGG网络&lt;/h2&gt;
&lt;h3 id=&quot;核心思想&quot;&gt;核心思想&lt;/h3&gt;
&lt;p&gt;能不能更深更大获得更好的精度？&lt;br&gt;
更多的全连接层&lt;br&gt;
更多的卷积层&lt;br&gt;
将卷积层组合成块&lt;br&gt;
&lt;img src=&quot;/2025/04/25/%E4%BD%BF</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://jiyexingzou.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="神经网络" scheme="https://jiyexingzou.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VGG" scheme="https://jiyexingzou.github.io/tags/VGG/"/>
    
  </entry>
  
  <entry>
    <title>近期目标与反思</title>
    <link href="https://jiyexingzou.github.io/2024/11/25/%E8%BF%91%E6%9C%9F%E7%9B%AE%E6%A0%87%E4%B8%8E%E5%8F%8D%E6%80%9D/"/>
    <id>https://jiyexingzou.github.io/2024/11/25/%E8%BF%91%E6%9C%9F%E7%9B%AE%E6%A0%87%E4%B8%8E%E5%8F%8D%E6%80%9D/</id>
    <published>2024-11-25T12:49:44.000Z</published>
    <updated>2025-12-31T14:15:34.998Z</updated>
    
    <content type="html"><![CDATA[<h2 id="近况">近况</h2><p>好久没更新个人网站了，来冒个泡。还是渐渐走上了正轨！</p><p>开始备赛，组好了队，甚至还有学长帮忙我哭死</p><p>反思：现在报的一些比赛还没有什么含金量，如果要面向就业需要打一些和嵌入式和ai相关的竞赛</p><p>放一张纱雾美图开心一下吧</p><p><img src="/2024/11/25/%E8%BF%91%E6%9C%9F%E7%9B%AE%E6%A0%87%E4%B8%8E%E5%8F%8D%E6%80%9D/74744256_p0_master1200.jpg" alt="前辈，那个我喜欢你！" title="前辈，那个我喜欢你！"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;近况&quot;&gt;近况&lt;/h2&gt;
&lt;p&gt;好久没更新个人网站了，来冒个泡。还是渐渐走上了正轨！&lt;/p&gt;
&lt;p&gt;开始备赛，组好了队，甚至还有学长帮忙我哭死&lt;/p&gt;
&lt;p&gt;反思：现在报的一些比赛还没有什么含金量，如果要面向就业需要打一些和嵌入式和ai相关的竞赛&lt;/p&gt;
&lt;p&gt;放一</summary>
      
    
    
    
    
    <category term="生活" scheme="https://jiyexingzou.github.io/tags/%E7%94%9F%E6%B4%BB/"/>
    
    <category term="反思" scheme="https://jiyexingzou.github.io/tags/%E5%8F%8D%E6%80%9D/"/>
    
    <category term="目标" scheme="https://jiyexingzou.github.io/tags/%E7%9B%AE%E6%A0%87/"/>
    
  </entry>
  
  <entry>
    <title>竞赛分享</title>
    <link href="https://jiyexingzou.github.io/2024/10/25/%E7%AB%9E%E8%B5%9B%E5%88%86%E4%BA%AB/"/>
    <id>https://jiyexingzou.github.io/2024/10/25/%E7%AB%9E%E8%B5%9B%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-25T08:14:15.000Z</published>
    <updated>2025-12-31T14:15:33.315Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述">概述</h2><p>服创，计设，华为ICT大赛，蓝桥杯等比赛经验分享</p><h1>1. 电子科技大学保研政策</h1><p>信软官网搜推免.</p><p>保研流程<br>排名百分之29左右<br>保研名额<br>科研经历</p><p>注意前五学期成绩排名<br>我还有3/5的机会,抓住机会</p><p>保研综合测评成绩</p><h1>学科竞赛</h1><p>能力培养:编程能力,技术能力,系统能力</p><p>就业：百度之星，大疆robomaster，robocon，华为ICT大赛。<br>竞赛中提出的算法创新<br>知识产权，专利，论文.</p><p>完善的竞赛保障</p><p>国三才不会处于劣势</p><p>就业向:<br>高水平企业赞助硬核比赛</p><p>服创，计设，蓝桥，信安。ppt大赛<br>网挑：中国高校计算机大赛</p><p>服创项目投计算机设计大赛</p><p>嵌入式:全国大学生嵌入式芯片与系统设计大赛</p><p>蓝桥杯：电子赛难度低于软件赛</p><p>ppt大赛<br>逻辑是否落地，需求是否真实，吹的天花乱坠<br>正态分布 = 高斯分布<br>算法创新，名字起的长一点。高大上</p><p>找人采访，比如找公安局的民警采访，<br>找公司让人签署合同，让别人感觉你的非常高级.</p><p>最重要的是要志同道合。</p><p>组队阶段保证志向，队友要负责，<br>确定方向是要保研</p><p>戴瑞婷老师！！！！</p><h2 id="组队">组队</h2><p>开发技术需要覆盖:技术栈：前后端，算法，(硬件)</p><p>软实力需要覆盖：审美水平在线(及其重要),视频剪辑，外箱点的，擅长演讲的，细心的<br>没有覆盖这些怎么办呢？<br>淘宝，小红书，咸鱼外包。<br>每个组一定会有优势方案</p><p>去小红书找做ppt的。<br>个人建议不要负责躲雨两个项目。</p><h2 id="团队合作">团队合作</h2><p>服创大赛命题，</p><p>尽量寒假内完成项目开发。前端做的很美观，精细.</p><p>算法，复现，改进，顶会高水平论文。</p><p>团队沟通<br>每周开会</p><p>使用飞书知识库<br>十分遍历的多人在线合作平台</p><p>多和指导老师，学长学姐沟通</p><h1>服创</h1><p>视频做的好<br>服务外包</p><p>有硬件是超级加分乡</p><h1>计设</h1><p>评委几乎没有懂计算机技术的</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;服创，计设，华为ICT大赛，蓝桥杯等比赛经验分享&lt;/p&gt;
&lt;h1&gt;1. 电子科技大学保研政策&lt;/h1&gt;
&lt;p&gt;信软官网搜推免.&lt;/p&gt;
&lt;p&gt;保研流程&lt;br&gt;
排名百分之29左右&lt;br&gt;
保研名额&lt;br&gt;
科研经历&lt;/p&gt;
&lt;p&gt;注意</summary>
      
    
    
    
    
    <category term="竞赛" scheme="https://jiyexingzou.github.io/tags/%E7%AB%9E%E8%B5%9B/"/>
    
    <category term="经验" scheme="https://jiyexingzou.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
    <category term="分享" scheme="https://jiyexingzou.github.io/tags/%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>大二竞赛展望</title>
    <link href="https://jiyexingzou.github.io/2024/10/22/%E5%A4%A7%E4%BA%8C%E7%AB%9E%E8%B5%9B%E5%B1%95%E6%9C%9B/"/>
    <id>https://jiyexingzou.github.io/2024/10/22/%E5%A4%A7%E4%BA%8C%E7%AB%9E%E8%B5%9B%E5%B1%95%E6%9C%9B/</id>
    <published>2024-10-22T07:44:53.000Z</published>
    <updated>2025-12-31T14:15:31.191Z</updated>
    
    <content type="html"><![CDATA[<h2 id="竞赛计划">竞赛计划</h2><ul><li>蓝桥杯我选择报Python组</li><li>服创赛和计算机设计赛我也打算参加</li></ul><p>希望一年以后能有好成果！</p><p>我也想要成为github全是绿点的人o(╥﹏╥)o</p><p><img src="/2024/10/22/%E5%A4%A7%E4%BA%8C%E7%AB%9E%E8%B5%9B%E5%B1%95%E6%9C%9B/fac2433f0441c3454ea4eed41c259074.jpg" alt="alt text" title="放一张图在这里激励我自己"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;竞赛计划&quot;&gt;竞赛计划&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;蓝桥杯我选择报Python组&lt;/li&gt;
&lt;li&gt;服创赛和计算机设计赛我也打算参加&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;希望一年以后能有好成果！&lt;/p&gt;
&lt;p&gt;我也想要成为github全是绿点的人o(╥﹏╥)o&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    
    <category term="竞赛" scheme="https://jiyexingzou.github.io/tags/%E7%AB%9E%E8%B5%9B/"/>
    
    <category term="规划" scheme="https://jiyexingzou.github.io/tags/%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>docker入门与配置</title>
    <link href="https://jiyexingzou.github.io/2024/10/19/docker%E5%85%A5%E9%97%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    <id>https://jiyexingzou.github.io/2024/10/19/docker%E5%85%A5%E9%97%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/</id>
    <published>2024-10-19T07:17:01.000Z</published>
    <updated>2025-12-31T14:15:29.495Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Docker官方文档">Docker官方文档</h2><p><a href="https://docs.docker.com/get-started/introduction/get-docker/">https://docs.docker.com/get-started/introduction/get-docker/</a></p><h2 id="First-Docker">First Docker</h2><p>[待补充]<br><a href="https://docs.docker.com/get-started/introduction/get-docker-desktop/">https://docs.docker.com/get-started/introduction/get-docker-desktop/</a></p><p>first docker</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Docker官方文档&quot;&gt;Docker官方文档&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/get-started/introduction/get-docker/&quot;&gt;https://docs.docker.com/get-st</summary>
      
    
    
    
    
    <category term="Docker" scheme="https://jiyexingzou.github.io/tags/Docker/"/>
    
    <category term="容器" scheme="https://jiyexingzou.github.io/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>批评与自我批评</title>
    <link href="https://jiyexingzou.github.io/2024/10/15/%E6%89%B9%E8%AF%84%E4%B8%8E%E8%87%AA%E6%88%91%E6%89%B9%E8%AF%84/"/>
    <id>https://jiyexingzou.github.io/2024/10/15/%E6%89%B9%E8%AF%84%E4%B8%8E%E8%87%AA%E6%88%91%E6%89%B9%E8%AF%84/</id>
    <published>2024-10-15T07:13:57.000Z</published>
    <updated>2025-12-31T14:15:26.705Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言">引言</h2><p>最近这几天，发现了我一个最大的问题，就是心存侥幸，总是在不该偷懒的地方偷懒，最近发生的两件事，让我深刻意识到了这样做的不好。</p><h3 id="未能在入党积极分子中成功结业">未能在入党积极分子中成功结业</h3><p><strong>事情经过</strong>:<br>起因：没有做每日日程提醒，导致忘记去上入党积极分子的第二次课<br>当时没有能够补救的措施，<strong>心存侥幸</strong>以为伪造辅导员签字可以请假，结果失败</p><p>即使是这样还没长教训，最后要求写两千字的学习证明，由于偷懒只写了1000字，并且书写很乱</p><h3 id="未能拿到1000奖学金">未能拿到1000奖学金</h3><p>这个纯纯是自己的锅，在申请奖学金页面，有一个申请理由，自己很敷衍的填了上去，结果最终没有通过专项奖学金。</p><h3 id="反思">反思</h3><p>该如何改正？</p><ol><li>制定每日日程表，做到有事情填上去及时提醒自己。</li><li>绝不能有这种懈怠的思想，这样会让你失去很多的机会</li></ol><p>此外，我还有每日不知道该做什么，三天打鱼，两天晒网的这种态势<br>可以称之为迷惘。</p><p>机会?<br>有同学找我打服创，正在找队友<br>我应该及时的去询问</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;最近这几天，发现了我一个最大的问题，就是心存侥幸，总是在不该偷懒的地方偷懒，最近发生的两件事，让我深刻意识到了这样做的不好。&lt;/p&gt;
&lt;h3 id=&quot;未能在入党积极分子中成功结业&quot;&gt;未能在入党积极分子中成功结业&lt;/h3&gt;
&lt;p&gt;&lt;st</summary>
      
    
    
    
    
    <category term="生活" scheme="https://jiyexingzou.github.io/tags/%E7%94%9F%E6%B4%BB/"/>
    
    <category term="反思" scheme="https://jiyexingzou.github.io/tags/%E5%8F%8D%E6%80%9D/"/>
    
  </entry>
  
  <entry>
    <title>K210快速上手</title>
    <link href="https://jiyexingzou.github.io/2024/10/08/K210%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
    <id>https://jiyexingzou.github.io/2024/10/08/K210%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</id>
    <published>2024-10-08T15:09:39.000Z</published>
    <updated>2025-12-31T14:15:15.540Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考教程">参考教程</h2><p><a href="https://blog.csdn.net/small_po_kid/article/details/113762110">https://blog.csdn.net/small_po_kid/article/details/113762110</a></p><p>咱先放个网址在这里，之后再填坑</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;参考教程&quot;&gt;参考教程&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/small_po_kid/article/details/113762110&quot;&gt;https://blog.csdn.net/small_po_kid/article</summary>
      
    
    
    
    
    <category term="K210" scheme="https://jiyexingzou.github.io/tags/K210/"/>
    
    <category term="教程" scheme="https://jiyexingzou.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Ollama本地部署</title>
    <link href="https://jiyexingzou.github.io/2024/10/08/Ollama%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"/>
    <id>https://jiyexingzou.github.io/2024/10/08/Ollama%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/</id>
    <published>2024-10-08T14:34:33.000Z</published>
    <updated>2025-12-31T14:15:13.506Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>Llama作为一个开源模型，在Ollama官网下载：<a href="https://ollama.com/">https://ollama.com/</a></p><p>clone Llama的git库即可直接本地部署AI<br>完整教程<br><a href="https://www.cnblogs.com/obullxl/p/18295202/NTopic2024071001">https://www.cnblogs.com/obullxl/p/18295202/NTopic2024071001</a></p><p>基于 WebUI 部署 Ollama 可视化对话界面<br>Ollama自带控制台对话界面体验总归是不太好，接下来部署 Web 可视化聊天界面：</p><p>下载并安装 Node.js 工具：<a href="https://nodejs.org/zh-cn">https://nodejs.org/zh-cn</a><br>下载ollama-webui工程代码：git clone <a href="https://github.com/ollama-webui/ollama-webui-lite">https://github.com/ollama-webui/ollama-webui-lite</a> ollama-webui<br>切换ollama-webui代码的目录：cd ollama-webui<br>设置 Node.js 工具包镜像源（下载提速）：npm config set registry <a href="http://mirrors.cloud.tencent.com/npm/">http://mirrors.cloud.tencent.com/npm/</a><br>安装 Node.js 依赖的工具包：npm install<br>最后，启动 Web 可视化界面：npm run dev</p><p><img src="/2024/10/08/Ollama%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/05.jpg" alt></p><p>如果看到以上输出，代表 Web 可视化界面已经成功了！</p><p>浏览器打开 Web 可视化界面：<a href="http://localhost:3000/">http://localhost:3000/</a></p><p><img src="/2024/10/08/Ollama%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/06.png" alt></p><p>接下来还可以通过python api和java api对于该大语言模型进行封装，上述网址中有，不再赘述</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;Llama作为一个开源模型，在Ollama官网下载：&lt;a href=&quot;https://ollama.com/&quot;&gt;https://ollama.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;clone Llama的git库即可直接本地部署AI&lt;br&gt;</summary>
      
    
    
    
    
    <category term="AI" scheme="https://jiyexingzou.github.io/tags/AI/"/>
    
    <category term="Ollama" scheme="https://jiyexingzou.github.io/tags/Ollama/"/>
    
    <category term="大语言模型" scheme="https://jiyexingzou.github.io/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="部署" scheme="https://jiyexingzou.github.io/tags/%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>国庆七天总结</title>
    <link href="https://jiyexingzou.github.io/2024/10/07/%E5%9B%BD%E5%BA%86%E4%B8%83%E5%A4%A9%E6%80%BB%E7%BB%93/"/>
    <id>https://jiyexingzou.github.io/2024/10/07/%E5%9B%BD%E5%BA%86%E4%B8%83%E5%A4%A9%E6%80%BB%E7%BB%93/</id>
    <published>2024-10-07T10:32:34.000Z</published>
    <updated>2025-12-31T14:15:08.049Z</updated>
    
    <content type="html"><![CDATA[<h1>我的国庆过的怎么样！</h1><p><em><strong>-国庆七天，我是怎么过的呢？我为什么要写一个总结呢？-</strong></em><br><strong>–写在文章开头</strong></p><p>现在是十月七号，也是国庆七天乐的最后一个晚上了，就我现在的感觉来看，我觉得我的国庆七天过得并不是很愉快。</p><p><strong>为什么!?</strong></p><p>可能是，我感觉，我在国庆的第一天，就没有想好我这几天究竟要干嘛，有一种既要又要的感觉。<br>可以说，假期的一开始，我是想要好好学习七天的。当时唯一给自己定的玩耍的一天就是十月四号的cd28.</p><p>但是，我干了些什么呢？<br>第一天，听说群友要去唱k，我就去了，实际上一共也没有唱几首歌，在那里扣了一个下午的手机。由于我的惰性，在吃喝玩乐回来之后，选择了直接回家。<br>第二天，在家里的我就更加放飞去玩了，但是心里又没有想好究竟玩什么。就在内耗中过去了一天，这一天去检查了一下身体，结果检查出来多项指标不正常，更让我忧心忡忡。<br>第三天，我打算的是早上回学校，但是由于我的拖沓，也是在浑浑噩噩之中玩到了下午，回到了学校，想着明天cd28，干脆今天也不学习了<br>第四天，逛了一天的展，晚上回来更是无心学习<br>第五天，终于打算要学习了，结果在图书馆一个下午就写了几道题，自己更多的时间在内耗和扣手机中度过，晚上被人叫出打了光棒，录了视频，我却还挺开心的？<br>第六天，无心学习，扣手机到12点起床，一个下午同样没做几道题，想要配置树莓派的环境没找到网线，想要学习java没看下去，自己心里还一直惦记着学习rust<br>第七天，早上10点起床，在宿舍床上内耗了一个下午，晚上到图书馆开始写了这个文档。</p><p>可以说，这几天，我是纯粹没有想好该怎么安排，导致七天玩也没玩开心，也没有学到什么。</p><p>这七天让我反思了一下，做事情得有一个自己的计划，告诉自己什么时候该玩，什么时候该学习？</p><p>真的是兴趣问题吗？说实话，现在我干的都是我自己目前最感兴趣的。但是现在还是一无所成，玩倒是玩了不少。</p><p><strong>现在我争取做到以下几点</strong></p><ol><li>放下手机</li><li>有计划的做事</li><li>早睡(这也是国庆七天最困扰我的)</li><li>找到自己真正想做的，做出一定的规模!</li></ol><h2 id="这就是我国庆七天的想法了">这就是我国庆七天的想法了</h2><p>最后放一张和泉纱雾吧</p><p><img src="/2024/10/07/%E5%9B%BD%E5%BA%86%E4%B8%83%E5%A4%A9%E6%80%BB%E7%BB%93/1.jpg" alt="可爱的和泉纱雾" title="在10月六号换了一个头像，很多人问我为什么换，可能是因为我想要洗心革面吧"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;我的国庆过的怎么样！&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;-国庆七天，我是怎么过的呢？我为什么要写一个总结呢？-&lt;/strong&gt;&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;–写在文章开头&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在是十月七号，也是国庆七天乐的最后一个晚上了，就我现</summary>
      
    
    
    
    
    <category term="总结" scheme="https://jiyexingzou.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
    <category term="生活" scheme="https://jiyexingzou.github.io/tags/%E7%94%9F%E6%B4%BB/"/>
    
    <category term="反思" scheme="https://jiyexingzou.github.io/tags/%E5%8F%8D%E6%80%9D/"/>
    
  </entry>
  
</feed>
