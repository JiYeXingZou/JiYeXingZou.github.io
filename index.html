
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8" />
    <title>Izumi Sagiri</title>
    <meta name="author" content="Izumi Sagiri" />
    <meta name="description" content="分享平时的技术和生活" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/avatar.jpg" />

    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>





<script src="/js/lib/home.js"></script>

<link rel="stylesheet" href="/css/main.css" />
 
<meta name="generator" content="Hexo 7.2.0"><link rel="alternate" href="/atom.xml" title="Izumi Sagiri" type="application/atom+xml">
</head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>IZUMI SAGIRI</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;IZUMI SAGIRI</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div id="home-head">
    <div
        id="home-background"
        ref="homeBackground"
        data-images="/images/background.png"
    ></div>
    <div id="home-info" @click="homeClick">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>Izumi Sagiri</h1>
                <h3>个人博客</h3>
                <h5>分享平时的技术和生活</h5>
            </div>
        </span>
    </div>
</div>
<div
    id="home-posts-wrap"
    ref="homePostsWrap"
    true
>
    <div id="home-posts">
        

<div class="post">
    <a href="/2025/12/31/2025%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/">
        <h2 class="post-title">2025年终总结</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/31
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h1>总结</h1>
<p>转眼间2025年就要过去了，是时候来一个年终总结了<br>
这一年发生了很多事情，有了两篇论文，找到了实习，遇见了很多人。<br>
时间真的过的好快。<br>
我自己对于2025年的评价呢，我认为，真的很幸福且充实。<br>
大二下的时候，组建了打比赛的团队。<br>
大家真的很努力，而且那个时候虽然事情很多很紧张，但是现在一回想，真的做了很多事情。<br>
暑假的时候，吵吵合合，也是最后调整过来了。<br>
现在已经适应了两个人的生活，感觉自己不再那么自私了。<br>
感觉自己离自己的目标又更近一步了。<br>
大三上，前面在焦虑和迷茫中度过<br>
10月份投的老师，没有了回信，陷入了深深的自我否定<br>
还好12月份，勇敢了一把，终于让实习有了着落。<br>
我有成熟一点了吗？</p>
<h1>未来的展望和一些想法</h1>
<p>明年想要好好去做这段实习，好好复习考研，我真的很害怕我会懈怠。</p>
<h2 id="实习">实习</h2>
<p>尽量参与到发表论文，真正获得提升</p>
<h2 id="明年考研需要做的：">明年考研需要做的：</h2>
<h3 id="1-6月底">1~6月底</h3>
<p>过完专业课的一轮和数学三本书<br>
408看完网课，做王道练习题，做一个梳理<br>
数一，过完三本书，做一些课后练习题<br>
英语，过完两轮单词</p>
<h3 id="7-12月">7~12月</h3>
<p>二轮，刷真题，九月份开政治</p>
<h1>尾声</h1>
<p>2025可能是我本科阶段最后一个好好体验大学生活的时候了，得好好的成为大人啊<br>
我感觉我的大学前两年，很多时候没有真正学到东西。后面我能改进一些吗？<br>
最后，放一张纱雾镇楼<br>
<img src="/2025/12/31/2025%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/%E5%92%8C%E6%B3%89%E7%BA%B1%E9%9B%BE-138780755.png" alt="alt text"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E6%80%BB%E7%BB%93/" style="color: #ff7d73">总结</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E5%B9%B4%E7%BB%88/" style="color: #03a9f4">年终</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E7%94%9F%E6%B4%BB/" style="color: #ff7d73">生活</a>
        </span>
        
    </div>
    <a href="/2025/12/31/2025%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/30/Hexo%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E9%85%8D%E7%BD%AE%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/">
        <h2 class="post-title">Hexo博客图床配置完全指南</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                技术教程
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="前言">前言</h2>
<p>在使用 Hexo 搭建博客时，很多小伙伴都会遇到两个问题：</p>
<ol>
<li><strong>本地图片占用空间过大</strong>：图片直接保存在本地和 GitHub 仓库，会导致仓库体积膨胀</li>
<li><strong>VSCode 粘贴图片不便</strong>：每次写博客时，粘贴的图片无法自动保存到对应的文章文件夹</li>
</ol>
<p>本文将介绍如何使用图床服务来优雅地解决这些问题。</p>
<h2 id="什么是图床？">什么是图床？</h2>
<p>图床是一种图片存储和托管服务，可以：</p>
<ul>
<li>节省本地和 GitHub 仓库空间</li>
<li>加快图片加载速度（配合 CDN）</li>
<li>支持图片外链，在 Markdown 中直接引用</li>
<li>方便图片管理和备份</li>
</ul>
<h2 id="解决方案概述">解决方案概述</h2>
<p>我们将使用以下工具组合：</p>
<ul>
<li><strong>PicList</strong>：强大的图床上传工具，支持多种图床服务</li>
<li><strong><a target="_blank" rel="noopener" href="http://SM.MS">SM.MS</a></strong>：免费图床服务（也可选择其他图床）</li>
<li><strong>VSCode 插件</strong>：实现编辑器内一键上传图片</li>
</ul>
<h2 id="详细配置步骤">详细配置步骤</h2>
<h3 id="第一步：安装-PicList">第一步：安装 PicList</h3>
<ol>
<li>访问 <a target="_blank" rel="noopener" href="https://github.com/Kuingsmile/PicList/releases">PicList Releases</a></li>
<li>下载最新的 Windows 安装包（<code>PicList-Setup-x.x.x.exe</code>）</li>
<li>双击安装，按提示完成安装</li>
</ol>
<p><strong>PicList 支持的图床服务：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://SM.MS">SM.MS</a>（免费，推荐新手）</li>
<li>imgloc（免费，无需注册）</li>
<li>阿里云 OSS（稳定，有免费额度）</li>
<li>腾讯云 COS（稳定，有免费额度）</li>
<li>GitHub（免费，但国内访问较慢）</li>
</ul>
<h3 id="第二步：注册并配置-SM-MS-图床">第二步：注册并配置 <a target="_blank" rel="noopener" href="http://SM.MS">SM.MS</a> 图床</h3>
<ol>
<li>访问 <a target="_blank" rel="noopener" href="https://sm.ms/home/register">SM.MS 注册页面</a> 注册账号</li>
<li>登录后访问 <a target="_blank" rel="noopener" href="https://sm.ms/home/apitoken">API Token 页面</a></li>
<li>点击生成 API Token，复制保存</li>
<li>打开 PicList 应用</li>
<li>点击 <strong>图床设置</strong> → <strong><a target="_blank" rel="noopener" href="http://SM.MS">SM.MS</a> 图床</strong></li>
<li>填入 API Token，点击确定</li>
</ol>
<h3 id="第三步：安装-VSCode-插件">第三步：安装 VSCode 插件</h3>
<p>在 VSCode 中打开博客项目：</p>
<ol>
<li>按 <code>Ctrl+Shift+X</code> 打开扩展面板</li>
<li>搜索 <strong>“Image/Picture Uploader (PicList)”</strong></li>
<li>点击安装</li>
</ol>
<h3 id="第四步：使用方法">第四步：使用方法</h3>
<p>配置完成后，在写博客时非常方便：</p>
<h4 id="方式一：剪贴板上传（最常用）">方式一：剪贴板上传（最常用）</h4>
<ol>
<li>截图或复制图片到剪贴板</li>
<li>在 Markdown 文件中按 <code>Ctrl+Alt+U</code></li>
<li>图片自动上传并插入 Markdown 链接</li>
</ol>
<h4 id="方式二：拖拽上传">方式二：拖拽上传</h4>
<p>直接拖拽图片到编辑器，自动上传并插入链接</p>
<h4 id="方式三：右键上传本地图片">方式三：右键上传本地图片</h4>
<p>右键点击图片文件，选择 “Upload Image with PicList”</p>
<h2 id="其他图床推荐">其他图床推荐</h2>
<h3 id="imgloc">imgloc</h3>
<ul>
<li><strong>优点</strong>：完全免费，无需注册</li>
<li><strong>缺点</strong>：稳定性稍差</li>
<li><strong>适用场景</strong>：临时图片存储，测试使用</li>
</ul>
<h3 id="阿里云-OSS">阿里云 OSS</h3>
<ul>
<li><strong>优点</strong>：稳定快速，国内访问速度快</li>
<li><strong>免费额度</strong>：40GB 存储，每月 5GB 流量</li>
<li><strong>适用场景</strong>：生产环境，追求稳定性</li>
</ul>
<h3 id="腾讯云-COS">腾讯云 COS</h3>
<ul>
<li><strong>优点</strong>：稳定快速，CDN 加速</li>
<li><strong>免费额度</strong>：50GB 存储（6 个月）</li>
<li><strong>适用场景</strong>：生产环境，国内用户为主</li>
</ul>
<h2 id="常见问题">常见问题</h2>
<h3 id="Q-图片上传失败怎么办？">Q: 图片上传失败怎么办？</h3>
<p>A: 检查以下几点：</p>
<ul>
<li>网络连接是否正常</li>
<li>API Token 是否正确</li>
<li>图床服务是否可用</li>
</ul>
<h3 id="Q-如何批量上传图片？">Q: 如何批量上传图片？</h3>
<p>A: 在 PicList 主界面可以批量选择图片上传，然后复制生成的 Markdown 链接</p>
<h3 id="Q-如何管理已上传的图片？">Q: 如何管理已上传的图片？</h3>
<p>A: 在图床服务的管理后台（如 <a target="_blank" rel="noopener" href="http://SM.MS">SM.MS</a>）或 PicList 的相册管理中可以查看和删除</p>
<h2 id="优化建议">优化建议</h2>
<ol>
<li><strong>图片压缩</strong>：上传前使用 <a target="_blank" rel="noopener" href="https://tinypng.com/">TinyPNG</a> 压缩图片</li>
<li><strong>定期清理</strong>：定期在图床后台删除不再使用的图片</li>
<li><strong>备份数据</strong>：重要图片建议备份到本地或云盘</li>
<li><strong>使用 CDN</strong>：如果使用阿里云 OSS 或腾讯云 COS，可以开启 CDN 加速</li>
</ol>
<h2 id="效果对比">效果对比</h2>
<p><strong>使用图床前：</strong></p>
<ul>
<li>本地图片：2MB+ 每张</li>
<li>GitHub 仓库：几百 MB</li>
<li>图片加载：较慢</li>
</ul>
<p><strong>使用图床后：</strong></p>
<ul>
<li>本地图片：0</li>
<li>GitHub 仓库：仅 Markdown 文本</li>
<li>图片加载：快速（配合 CDN）</li>
</ul>
<h2 id="总结">总结</h2>
<p>通过配置图床服务，我们优雅地解决了 Hexo 博客的图片管理问题：</p>
<ul>
<li>释放了本地和仓库空间</li>
<li>实现了 VSCode 一键上传图片</li>
<li>提升了博客加载速度</li>
</ul>
<p>如果你在配置过程中遇到问题，欢迎在评论区交流！</p>
<h2 id="参考链接">参考链接</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Kuingsmile/PicList">PicList GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://sm.ms/">SM.MS 官网</a></li>
<li><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo 官方文档</a></li>
</ul>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/Hexo/" style="color: #ff7d73">Hexo</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96/" style="color: #00bcd4">博客优化</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E5%9B%BE%E5%BA%8A/" style="color: #ff7d73">图床</a>
        </span>
        
    </div>
    <a href="/2025/12/30/Hexo%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E9%85%8D%E7%BD%AE%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/">
        <h2 class="post-title">12.14-25日论文学习报告</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                学术研究
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/25
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p><strong>报告人:王子通 | 2025/12/25</strong></p>
<h1>MatchTime 系列论文深度笔记</h1>
<h1>第一篇论文 MatchTime: Towards Automatic Soccer Game Commentary Generation</h1>
<h2 id="核心痛点：消失的“16秒”">核心痛点：消失的“16秒”</h2>
<p>在足球视频领域，传统的解说词数据存在严重的<strong>音画不同步</strong>。由于原始数据大多抓取自实时文字直播，解说词往往比实际进球画面晚了 <strong>16.63 秒</strong>甚至更多。如果直接用这种“脏数据”训练，AI 只会学会“马后炮”。</p>
<hr>
<h2 id="第一章：数据治本——如何通过数学实现“降维打击”">第一章：数据治本——如何通过数学实现“降维打击”</h2>
<p>论文的核心贡献在于 <strong>Section 3.2 (Temporal Alignment Pipeline)</strong>，它展示了如何用一套自动化的管线将滞后的文本“拽”回正确的帧。</p>
<h3 id="1-亲和力矩阵-Affinity-Matrix-：连连看的底牌">1. 亲和力矩阵 (Affinity Matrix)：连连看的底牌</h3>
<p>为了对齐视频帧（Visual Frames）和解说词（Text Captions），作者引入了 <strong>Affinity Matrix  $\mathbb{A}$</strong>。</p>
<ul>
<li><strong>它是怎么来的？</strong> 假设视频有$n$ 帧，文本有 $k$ 句，矩阵的大小就是$k \times n$ 。</li>
</ul>
<h3 id="核心公式推导：亲和力矩阵-Affinity-Matrix">核心公式推导：亲和力矩阵 (Affinity Matrix)</h3>
<p>在计算视频帧 $V_j$ 与文本 $C_i$ 的相似度时，公式表达为：</p>
<p>$$\mathbb{A}[i, j] = \frac{C_i \cdot V_j^T}{||C_i|| \cdot ||V_j|| \cdot \tau}$$</p>
<p><strong>公式拆解：</strong></p>
<ul>
<li><strong>分子 ($C_i \cdot V_j^T$)</strong>：特征向量的点积，衡量方向一致性。</li>
<li><strong>分母 ($||C_i|| \cdot ||V_j||$)</strong>：$L_2$ 范数归一化，确保计算的是<strong>余弦相似度</strong>。</li>
<li><strong>$\tau$</strong>：温度参数，用来控制相似度分布的平滑度。</li>
<li><strong>深度解析</strong>：</li>
<li>** 是什么？** 这是向量的 ** 范数**（模长）。之所以要除以它，是为了进行<strong>归一化</strong>，将计算锁定为<strong>余弦相似度</strong>。我们只关心文本和画面的“语义方向”是否一致，而不关心特征向量本身的绝对大小。</li>
<li><strong>为什么要算这个？</strong> 通过寻找矩阵每一行中的最大值（），模型能自动锁死每一句解说词对应的“高光时刻”。</li>
</ul>
<hr>
<h2 id="第二章：模型架构——MatchVoice-的“翻译”逻辑">第二章：模型架构——MatchVoice 的“翻译”逻辑</h2>
<p>MatchVoice 的本质是一个<strong>多模态大模型 (MLLM)</strong>。它通过一套精密设计的组件，将视频“翻译”成文字。</p>
<h3 id="1-为什么视觉编码器-Visual-Encoder-要冻结？">1. 为什么视觉编码器 (Visual Encoder) 要冻结？</h3>
<p>在架构图中，你会看到视觉部分（如 CLIP 或 Baidu 特征）被打上了“雪花”图标（Frozen）。</p>
<ul>
<li><strong>策略</strong>：冻结预训练好的编码器可以保持其强大的通用特征提取能力，同时大幅降低训练成本。</li>
</ul>
<h3 id="2-Learnable-Queries-Attention：精准探测器">2. Learnable Queries &amp; Attention：精准探测器</h3>
<ul>
<li><strong>Learnable Queries</strong>：它们不是来自视频，而是模型内置的“探测员”。</li>
<li><strong>自注意力 (Self-Attention)</strong>：让这群“探测员”在出发前先开个会，分工合作（比如有的看人，有的看球）。</li>
<li><strong>交叉注意力 (Cross-Attention)</strong>：这是关键！探测员拿着清单去视频特征（超市货架）里取货，把散落在时空中的信息吸收到 Query 向量中。<br>
<img src="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/image-4.png" alt="alt text"></li>
</ul>
<h3 id="3-从投影到生成：MLP-与-Prefix-Tokens">3. 从投影到生成：MLP 与 Prefix Tokens</h3>
<ul>
<li><strong>MLP 的翻译官作用</strong>：视觉特征与 LLM 的维度往往不匹配。<strong>MLP (Projection Layer)</strong> 就像转换插头，将视觉特征投影到 LLM 能听懂的空间。</li>
<li><strong>Prefix Tokens (紫色方块)</strong>：这是 MLP 输出的唯一成果。它们作为“视觉前缀”喂给 LLM（如 LLaMA-3）。</li>
<li><strong>生成逻辑:$C = \Psi_{dec}(\Psi_{proj}(F))$。</strong>：。LLM 接收到视觉前缀后，开始顺着这个背景一个词一个词地吐出蓝色的 <strong>Commentary Tokens</strong>。</li>
</ul>
<hr>
<h2 id="第三章：评估的“金标准”——SN-Caption-test-align">第三章：评估的“金标准”——SN-Caption-test-align</h2>
<p>为了证明 AI 真的看懂了球，作者没有使用模糊的原始数据进行评估，而是打造了 <strong>SN-Caption-test-align</strong>。</p>
<ul>
<li><strong>本质</strong>：这是对 SoccerNet-Caption 的<strong>人工精修版</strong>。</li>
<li><strong>意义</strong>：它不仅是一个数据集，更是一个“公正的考官”。只有在时间戳绝对准确的考卷上拿到高分（如 <strong>CIDEr</strong> 分数的暴涨），才能证明对齐管线的有效性。</li>
</ul>
<hr>
<ul>
<li><strong>Baidu 特征最强</strong>：实验证明，相比通用的 CLIP，这种在足球领域“深造”过的模型（Baidu Soccer Embeddings）作为视觉编码器效果最佳。</li>
<li><strong>数据 &gt; 模型</strong>：即便使用基础的 ResNet，只要用了对齐后的 MatchTime 数据集，表现甚至能超越在脏数据上跑的高级模型。</li>
</ul>
<hr>
<h2 id="第二篇论文-Towards-Universal-Soccer-Video-Understanding">第二篇论文 Towards Universal Soccer Video Understanding</h2>
<p>第二篇论文在第一篇论文的基础上提出了SoccerReplay-1988数据集。<br>
并且提出了足球专用的解码器MatchVison</p>
<h3 id="SoccerReplay-19886-Dataset">SoccerReplay-19886 Dataset</h3>
<p>这篇文章阐述了这个作者是如何做这个数据集的，将视频分为上下两场，从starting at kick off开始。并且采用第一篇文章的MatchTime的对齐方式，通过手动进行人工对齐</p>
<p><img src="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/image-5.png" alt="alt text"></p>
<h3 id="对于模型我自己的理解">对于模型我自己的理解:</h3>
<p>本质上就是一个改进的video transformer</p>
<h4 id="Token-Embedding">Token Embedding</h4>
<p><strong>空间切分：</strong> 每一帧图像 $ i $ 被切分成 $ M $ 个不重叠的小方块（Patches）。这就像把一张照片剪成方格阵列。</p>
<p><strong>线性映射 ($\Phi_{Emb}$)：</strong> 每个小方块被拉平并转换成一个维度为 $D$ 的向量。</p>
<p><strong>双重位置编码 (Position Embedding)：</strong> 这是关键。</p>
<ul>
<li><strong>空间位置编码 ($e_s^{pos}$)</strong>：告诉模型这个方块在画面的哪个位置（左上还是右下）。</li>
<li><strong>时间位置编码 ($e_t^{pos}$)</strong>：在处理完整个视频序列后叠加，告诉模型这一组特征属于视频的第几秒。</li>
</ul>
<p><strong>[CLS] 标记：</strong> 每一帧都会加入一个特殊的 <code>[cls]</code> 标记，专门用来汇总这一帧的全局信息。</p>
<h4 id="时空注意力模块">时空注意力模块</h4>
<p><strong>时间自注意力 ($\phi_t$)：</strong></p>
<ul>
<li><strong>操作：</strong> 只在不同帧的<strong>相同空间位置</strong>的 Token 之间进行计算。</li>
<li><strong>目的：</strong> 追踪动作。例如，第1帧里的足球在左边，第2帧里的足球移动到了中间，时间注意力负责捕捉这个“移动”轨迹。</li>
</ul>
<p><strong>空间自注意力 ($\phi_s$)：</strong></p>
<ul>
<li><strong>操作：</strong> 只在<strong>同一帧内部</strong>的不同 Token 之间进行计算。</li>
<li><strong>目的：</strong> 理解布局。例如，识别出这一帧画面里哪是球员、哪是球门、哪是裁判。</li>
</ul>
<p><strong>交替堆叠 ($K$ 次)：</strong> 通过多次交替循环，模型既能看清每一帧的细节，又能理解动作在时间上的逻辑。</p>
<h4 id="聚合层-Aggregation-Layer">聚合层(Aggregation Layer)</h4>
<p>在经过复杂的注意力计算后，模型需要把海量的数据“浓缩”成一个简洁的特征向量，供下游任务使用。</p>
<ul>
<li><strong>空间聚合：</strong> 利用聚合层 $\Phi_{Agg}$，将每一帧中散落在各个 Patch 里的信息，全部压缩到该帧的 <code>[cls]</code> 标记中（得到 $\hat{F}_i^{CLS}$）。</li>
<li><strong>最终表示 ($F_V$)：</strong> 将所有帧的 <code>[cls]</code> 标记拼接起来。
<ul>
<li><strong>结果：</strong> 得到的 $F_V$ 是一个矩阵，它每一行代表一帧的精华，整组矩阵代表了整个视频片段的精华。</li>
</ul>
</li>
</ul>
<h3 id="预训练层">预训练层</h3>
<h3 id="监督分类-Supervised-Classification-mathcal-L-sup"><strong>监督分类 (Supervised Classification, $\mathcal{L}_{sup}$)</strong></h3>
<ul>
<li><strong>做法：</strong> 将提取出的视频特征 $F_V$ 通过一个<strong>时间自注意力层</strong>，汇总到一个可学习的 <code>[cls]</code> 标记中。</li>
<li><strong>计算：</strong> 这个标记被输入线性分类器，使用<strong>交叉熵损失 (Cross-Entropy Loss)</strong> 进行训练。</li>
<li><strong>目的：</strong> 让模型学会“看图识事”，即直接根据画面判断这是进球还是犯规。</li>
</ul>
<h3 id="视频-语言对比学习-Video-Language-Contrastive-Learning-mathcal-L-contra"><strong>视频-语言对比学习 (Video-Language Contrastive Learning, $\mathcal{L}_{contra}$)</strong></h3>
<ul>
<li><strong>做法：</strong> 对视频特征进行平均池化得到 $F_V^{Avg}$，同时用文本编码器处理解说词 $C$。</li>
<li><strong>创新点：</strong> 借鉴了 <strong>SigLIP</strong> 的损失函数。</li>
<li><strong>正样本优化：</strong> 针对足球比赛中经常出现高度相似的解说（如“比赛开始”），模型将同一批次中相似度高的文本都视为正样本，增强了鲁棒性。</li>
<li><strong>目的：</strong> 建立视觉与文本的语义联系，为下游的解说生成任务打好基础。</li>
</ul>
<h3 id="疑问：">疑问：</h3>
<h4 id="为什么是监督分类？">为什么是监督分类？</h4>
<h3 id="1-足球语义的复杂性与明确性">1. 足球语义的复杂性与明确性</h3>
<ul>
<li><strong>语义明确：</strong> 足球比赛中的关键事件（如进球、黄牌、换人）都有非常明确的官方定义和边界。</li>
<li><strong>监督优势：</strong> 监督分类通过使用专家标注的 <strong>Event Labels</strong>，能直接“教会”模型识别这些高层语义特征。相比之下，无监督学习（如传统的聚类或掩码建模）可能只会让模型学会识别“草坪是绿色的”或“球员在跑动”，而难以自发理解“这是一个越位”这种复杂的逻辑关系。</li>
</ul>
<h3 id="2-预训练目标的互补性">2. 预训练目标的互补性</h3>
<p>根据文本，MatchVision 并不是只用监督学习，而是采用了<strong>混合策略</strong>：</p>
<ul>
<li><strong>监督分类 ($\mathcal{L}_{sup}$)</strong>：负责建立<strong>视觉特征与官方动作标签</strong>的强关联。</li>
<li><strong>对比学习 ($\mathcal{L}_{contra}$)</strong>：这其实具有一定的“弱监督”或“自监督”性质，它通过**视频与解说词（Textual Commentaries）**的匹配，让模型学习更丰富的语言描述能力。</li>
<li><strong>结合效果：</strong> 监督分类提供了“硬准则”（这是什么动作），而对比学习提供了“软语义”（这个动作怎么描述）。</li>
</ul>
<h3 id="3-提升特征的判别力-Discriminative-Power">3. 提升特征的判别力 (Discriminative Power)</h3>
<ul>
<li><strong>类内与类间差异：</strong> 足球视频中，很多动作看起来极其相似（例如，普通的传球和助攻传球在视觉上可能只有微小区别）。</li>
<li><strong>监督的作用：</strong> 使用交叉熵损失（Cross-Entropy Loss）的监督训练，会强制模型在特征空间中拉开不同事件类别的距离，从而在下游任务（如犯规识别）中表现得更精准。</li>
</ul>
<h3 id="4-行业数据集的现状">4. 行业数据集的现状</h3>
<ul>
<li><strong>标注资源：</strong> 足球领域拥有如 SoccerNet 这样大规模且高质量的标注数据集。</li>
<li><strong>效率考量：</strong> 既然已经有了现成的“正确答案（Labels）”，直接使用监督学习进行预训练，比让模型在海量无标注视频中漫无目的地探索（无监督）要高效得多。</li>
</ul>
<h4 id="什么是cls和cmt">什么是cls和cmt</h4>
<h2 id="1-CLS-Event-Classification-事件分类">1. CLS (Event Classification - 事件分类)</h2>
<p><strong>CLS</strong> 是 <strong>Classification</strong> 的缩写，主要负责“看图识事”，即识别视频中发生了什么特定事件。</p>
<ul>
<li><strong>核心功能：</strong> 将输入的足球视频片段归类为预定义的事件标签，例如“进球”、“角球”、“黄牌”或“换人”。</li>
<li><strong>实现机制：</strong> * 模型会引入一个可学习的 <strong>[cls] token</strong>，通过<strong>时间自注意力机制</strong>（Temporal Self-attention）汇总整段视频的时空特征。
<ul>
<li>该特征随后被送入一个<strong>线性分类器</strong>（Linear Classifier）进行处理。</li>
</ul>
</li>
<li><strong>输出结果：</strong> 给出各个事件类别的概率分布，通常选取概率最高的一个作为最终判定结果（如：Type: “Yellow card”）。</li>
</ul>
<hr>
<h2 id="2-CMT-Commentary-Generation-解说生成">2. CMT (Commentary Generation - 解说生成)</h2>
<p><strong>CMT</strong> 是 <strong>Commentary</strong> 的缩写，主要负责“见图说话”，即生成像专业解说员一样的自然语言描述。</p>
<ul>
<li><strong>核心功能：</strong> 自动为视频片段编写一段符合赛况的叙述性文字。</li>
<li><strong>实现机制：</strong>
<ul>
<li>使用 <strong>Perceiver 聚合器</strong> 将复杂的视觉特征浓缩，并通过 <strong>MLP</strong> 映射为<strong>前缀嵌入</strong>（Prefix Embeddings）。</li>
<li>这些视觉嵌入被输入到**大语言模型（LLM）**中，引导 LLM 根据画面内容生成文本。</li>
</ul>
</li>
<li><strong>输出结果：</strong> 一段完整的句子，例如：“[REFEREE] shows a yellow card to [PLAYER]…”。</li>
</ul>
<h3 id="下游任务层">下游任务层</h3>
<p>预训练完成后，视觉编码器被“冻结”或作为骨干网络，通过不同的<strong>预测头 ($\Psi$)</strong> 来适配具体任务：</p>
<h3 id="事件分类-Psi-cls"><strong>事件分类 ($\Psi_{cls}$)</strong></h3>
<ul>
<li><strong>机制：</strong> 结构与预训练的监督学习类似，使用时间自注意力聚合特征。</li>
<li><strong>训练逻辑：</strong> 在<strong>冻结视觉编码器</strong>的情况下，仅训练线性分类器。</li>
<li><strong>输出：</strong> 给出视频属于哪种事件（如：角球、黄牌）的概率分布。</li>
</ul>
<h3 id="解说生成-Psi-Cmt"><strong>解说生成 ($\Psi_{Cmt}$)</strong></h3>
<ul>
<li>
<p><strong>核心组件：</strong> <strong>Perceiver 聚合器</strong> + <strong>MLP</strong> + <strong>LLM（大语言模型）</strong>。</p>
</li>
<li>
<p>流程： 1. Perceiver 将海量的视觉特征压缩。</p>
<p>\2. MLP 将其映射为 LLM 能听懂的“前缀嵌入（Prefix Embeddings）”。</p>
<p>\3. LLM 根据这些“视觉前缀”像写作文一样生成解说词。</p>
</li>
<li>
<p><strong>损失函数：</strong> 使用负对数似然损失（Next-Token Prediction）。</p>
</li>
</ul>
<h3 id="犯规识别-Psi-Foul"><strong>犯规识别 ($\Psi_{Foul}$)</strong></h3>
<ul>
<li><strong>输入：</strong> 足球比赛中常见的**多视角（Multi-view）**视频。</li>
<li><strong>处理：</strong> 使用池化技术（Max/Avg Pooling）将多视角特征整合为一个向量。</li>
<li><strong>双任务输出：</strong> 使用一个共享的 MLP 接两个分类器，同时预测：
<ol>
<li><strong>犯规类型</strong>（如：铲球犯规、手球等，共 8 种）。</li>
<li><strong>严重程度</strong>（如：口头警告、黄牌、红牌等，共 4 级）。</li>
</ol>
</li>
</ul>
<p><strong>为什么要使用MLP</strong></p>
<p>实现跨模态的特征对齐，不需要更强大的模型，简单的MLP足够胜任模态对齐工作</p>
<h3 id="实验部分">实验部分</h3>
<p>基于他上面自己的soccer Replay 1988数据集进行实验</p>
<p>MatchVision在分类这个任务是达到了**82.5%**的准确率</p>
<p>证明对比学习比监督学习的效果更好</p>
<p>并且MatchVision在foul recongition方面，即使冻结了视觉编码器，也和顶尖模型不相上下</p>
<h3 id="最后部分">最后部分</h3>
<p>使用了LoRA技术调教LLM</p>
<p>这篇论文有三个比较大的贡献</p>
<p><strong>新资源</strong>：造出了迄今为止最大的足球数据集 <strong>SoccerReplay-1988</strong>。</p>
<p><strong>新模型</strong>：开发了专门针对足球时空特征的编码器 <strong>MatchVision</strong>。</p>
<p><strong>新标杆</strong>：在分类、解说、犯规识别等多个任务上都达到了<strong>世界领先水平 (SOTA)</strong>。</p>
<h2 id="Multi-Agent-System-for-Comprehensive-Soccer-Understanding">Multi-Agent System for Comprehensive Soccer Understanding</h2>
<h3 id="引言">引言</h3>
<p>论文在引言部分介绍了现在的研究在足球理解研究的一些挑战</p>
<p>在推理任务上比较的局限（局限于视觉分析而缺少了推理）</p>
<p>以及模型过于的碎片化和专家化</p>
<p><strong>这篇文章主要有四个贡献</strong></p>
<p><strong>构建了 SoccerWiki 知识库</strong>：这是第一个大规模的多模态足球知识库，集成了关于球员、球队、裁判和场地的丰富领域知识，旨在支持知识驱动的推理任务 。该库包含 9,471 名球员、266 支球队、202 名裁判和 235 个场地的详细信息 。</p>
<p><strong>建立了 SoccerBench 基准测试集</strong>：这是目前最大且最全面的足球领域专项基准 。它通过自动化的数据策划和人工验证构建，包含约 1 万个多模态（文本、图像、视频）选择题对，涵盖了背景知识、比赛局势识别、犯规识别等 13 项不同的足球分析任务 。</p>
<p><strong>开发了 SoccerAgent 多智能体系统</strong>：这是一种新型的多智能体协作系统，通过将复杂的足球问题分解为多个可执行的子任务来解决问题 。它利用了 SoccerWiki 的领域专家知识，并能够调用 18 个专项工具进行协作推理 。</p>
<p><strong>进行了广泛的评估与对比</strong>：作者在 SoccerBench 上将 SoccerAgent 与 11 种代表性的多模态大语言模型（MLLMs，如 GPT-4o、Claude 3.7、Gemini 2.0 等）进行了深入对比 。评估结果突显了该智能体系统在处理复杂、知识密集型足球任务中的优越性 。101</p>
<h3 id="介绍soccerBench">介绍soccerBench</h3>
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>包含任务 (Index)</strong></th>
<th><strong>考查重点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>纯文本推理</strong> (TextQA)</td>
<td><strong>Q1</strong> 背景知识, <strong>Q2</strong> 比赛局势</td>
<td>考查模型是否掌握了球员历史、转会、比赛战术等“足球常识”。</td>
</tr>
<tr>
<td><strong>图像视觉感知</strong> (ImageQA)</td>
<td><strong>Q3</strong> 相机状态分类, <strong>Q4</strong> 图片背景知识, <strong>Q5</strong> 球衣号码识别, <strong>Q6</strong> 比分与时间识别</td>
<td>考查模型对单张转播截图的解析力，例如识别“这是哪场比赛”、“这是几号球员”。</td>
</tr>
<tr>
<td><strong>视频动态分析</strong> (VideoQA)</td>
<td><strong>Q7</strong> 相机切换, <strong>Q8</strong> 回放定位, <strong>Q9</strong> 动作分类, <strong>Q10/Q11</strong> 评论生成与理解, <strong>Q12</strong> 球衣颜色识别, <strong>Q13</strong> 多视角犯规识别</td>
<td><strong>最难的部分</strong>。考查模型能否理解动作的连贯性，并根据规则做出裁判级别的判断（如 Q13 判定是否犯规）。</td>
</tr>
</tbody>
</table>
<h3 id="研究动机">研究动机</h3>
<p>作者认为目前足球AI时效性不足，评价碎片化</p>
<p>作者构建了SoccerWIKI，并且在此基础上构建了SoccerBench</p>
<h4 id="Data-Curation">Data Curation</h4>
<p>团队采用不同的策略生成原始问答对（模版生成，大模型生成）</p>
<p>并且转化成四选一的选择题</p>
<p>最后通过自动化合成再经过人工筛选，组成了<strong>SoccerBench</strong></p>
<h3 id="SoccerAgent">SoccerAgent</h3>
<p><img src="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/image-20251225220605344.png" alt="SoccerAgent架构图"></p>
<p>论文的核心部分</p>
<h4 id="基于DeepSeek-V3的主模块协同工作">基于DeepSeek-V3的主模块协同工作</h4>
<p><strong>规划者 ($\mathcal{A}_{plan}$)</strong>：负责“思考”。它接收问题后，并不直接回答，而是分析需要哪些步骤，从工具包里挑选出最合适的<strong>工具链</strong>。</p>
<p><strong>执行者 ($\mathcal{A}_{exec}$)</strong>：负责“动手”。它按照规划好的顺序，一个接一个地运行工具。每一步都会参考之前的执行历史（$\mathcal{H}_{i}$），从而实现上下文感知的自适应调整。</p>
<h4 id="ToolBox">ToolBox</h4>
<p><strong>12 个足球专项工具</strong>：</p>
<p><strong>基础分析</strong>：动作分类器、评论生成 。</p>
<p><strong>检索专家</strong>：比赛搜索、比赛历史/信息检索、<strong>人脸识别</strong>（从 SoccerWiki 匹配球员） 。</p>
<p><strong>感知专家</strong>：相机状态检测、<strong>球衣号码/颜色识别</strong>、比分和时间识别 。</p>
<p><strong>高级裁判</strong>：<strong>犯规识别</strong>（通过多视角投票机制模拟 VAR）和回放定位 。</p>
<p><strong>6 个通用解析工具</strong>：</p>
<p>包括<strong>帧选择</strong>（将视频转为关键帧）、语义分割（定位特定物体）、实体搜索和文本检索等 。</p>
<h3 id="实验部分-2">实验部分</h3>
<p>比较重点的：我认为是容错能力</p>
<p><strong>自主调整：</strong> 执行者 ($\mathcal{A}_{exec}$) 在发现第一步失败后，并没有卡死，而是根据历史上下文自主调整策略，改用“比赛搜索”工具成功找回了所需信息 。</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" style="color: #00a596">论文笔记</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/MatchTime/" style="color: #03a9f4">MatchTime</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/SoccerNet/" style="color: #ffa2c4">SoccerNet</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E8%B6%B3%E7%90%83AI/" style="color: #03a9f4">足球AI</a>
        </span>
        
    </div>
    <a href="/2025/12/25/12.14-25%E6%97%A5%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/">
        <h2 class="post-title">别再说 AI 不懂球：MatchTime 系列论文深度笔记</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                学术研究
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/23
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h1>别再说 AI 不懂球：MatchTime 系列论文深度笔记（一）</h1>
<h2 id="核心痛点：消失的“16秒”">核心痛点：消失的“16秒”</h2>
<p>在足球视频领域，传统的解说词数据存在严重的<strong>音画不同步</strong>。由于原始数据大多抓取自实时文字直播，解说词往往比实际进球画面晚了 <strong>16.63 秒</strong>甚至更多。如果直接用这种“脏数据”训练，AI 只会学会“马后炮”。</p>
<hr>
<h2 id="第一章：数据治本——如何通过数学实现“降维打击”">第一章：数据治本——如何通过数学实现“降维打击”</h2>
<p>论文的核心贡献在于 <strong>Section 3.2 (Temporal Alignment Pipeline)</strong>，它展示了如何用一套自动化的管线将滞后的文本“拽”回正确的帧。</p>
<h3 id="1-亲和力矩阵-Affinity-Matrix-：连连看的底牌">1. 亲和力矩阵 (Affinity Matrix)：连连看的底牌</h3>
<p>为了对齐视频帧（Visual Frames）和解说词（Text Captions），作者引入了 <strong>Affinity Matrix  $\mathbb{A}$</strong>。</p>
<ul>
<li><strong>它是怎么来的？</strong> 假设视频有$n$ 帧，文本有 $k$ 句，矩阵的大小就是$k \times n$ 。</li>
</ul>
<h3 id="核心公式推导：亲和力矩阵-Affinity-Matrix">核心公式推导：亲和力矩阵 (Affinity Matrix)</h3>
<p>在计算视频帧 $V_j$ 与文本 $C_i$ 的相似度时，公式表达为：</p>
<p>$$\mathbb{A}[i, j] = \frac{C_i \cdot V_j^T}{||C_i|| \cdot ||V_j|| \cdot \tau}$$</p>
<p><strong>公式拆解：</strong></p>
<ul>
<li><strong>分子 ($C_i \cdot V_j^T$)</strong>：特征向量的点积，衡量方向一致性。</li>
<li><strong>分母 ($||C_i|| \cdot ||V_j||$)</strong>：$L_2$ 范数归一化，确保计算的是<strong>余弦相似度</strong>。</li>
<li><strong>$\tau$</strong>：温度参数，用来控制相似度分布的平滑度。</li>
<li><strong>深度解析</strong>：</li>
<li>** 是什么？** 这是向量的 ** 范数**（模长）。之所以要除以它，是为了进行<strong>归一化</strong>，将计算锁定为<strong>余弦相似度</strong>。我们只关心文本和画面的“语义方向”是否一致，而不关心特征向量本身的绝对大小。</li>
<li><strong>为什么要算这个？</strong> 通过寻找矩阵每一行中的最大值（），模型能自动锁死每一句解说词对应的“高光时刻”。</li>
</ul>
<hr>
<h2 id="第二章：模型架构——MatchVoice-的“翻译”逻辑">第二章：模型架构——MatchVoice 的“翻译”逻辑</h2>
<p>MatchVoice 的本质是一个<strong>多模态大模型 (MLLM)</strong>。它通过一套精密设计的组件，将视频“翻译”成文字。</p>
<h3 id="1-为什么视觉编码器-Visual-Encoder-要冻结？">1. 为什么视觉编码器 (Visual Encoder) 要冻结？</h3>
<p>在架构图中，你会看到视觉部分（如 CLIP 或 Baidu 特征）被打上了“雪花”图标（Frozen）。</p>
<ul>
<li><strong>策略</strong>：冻结预训练好的编码器可以保持其强大的通用特征提取能力，同时大幅降低训练成本。</li>
</ul>
<h3 id="2-Learnable-Queries-Attention：精准探测器">2. Learnable Queries &amp; Attention：精准探测器</h3>
<ul>
<li><strong>Learnable Queries</strong>：它们不是来自视频，而是模型内置的“探测员”。</li>
<li><strong>自注意力 (Self-Attention)</strong>：让这群“探测员”在出发前先开个会，分工合作（比如有的看人，有的看球）。</li>
<li><strong>交叉注意力 (Cross-Attention)</strong>：这是关键！探测员拿着清单去视频特征（超市货架）里取货，把散落在时空中的信息吸收到 Query 向量中。<br>
<img src="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/image-4.png" alt="alt text"></li>
</ul>
<h3 id="3-从投影到生成：MLP-与-Prefix-Tokens">3. 从投影到生成：MLP 与 Prefix Tokens</h3>
<ul>
<li><strong>MLP 的翻译官作用</strong>：视觉特征与 LLM 的维度往往不匹配。<strong>MLP (Projection Layer)</strong> 就像转换插头，将视觉特征投影到 LLM 能听懂的空间。</li>
<li><strong>Prefix Tokens (紫色方块)</strong>：这是 MLP 输出的唯一成果。它们作为“视觉前缀”喂给 LLM（如 LLaMA-3）。</li>
<li><strong>生成逻辑:$C = \Psi_{dec}(\Psi_{proj}(F))$。</strong>：。LLM 接收到视觉前缀后，开始顺着这个背景一个词一个词地吐出蓝色的 <strong>Commentary Tokens</strong>。</li>
</ul>
<hr>
<h2 id="第三章：评估的“金标准”——SN-Caption-test-align">第三章：评估的“金标准”——SN-Caption-test-align</h2>
<p>为了证明 AI 真的看懂了球，作者没有使用模糊的原始数据进行评估，而是打造了 <strong>SN-Caption-test-align</strong>。</p>
<ul>
<li><strong>本质</strong>：这是对 SoccerNet-Caption 的<strong>人工精修版</strong>。</li>
<li><strong>意义</strong>：它不仅是一个数据集，更是一个“公正的考官”。只有在时间戳绝对准确的考卷上拿到高分（如 <strong>CIDEr</strong> 分数的暴涨），才能证明对齐管线的有效性。</li>
</ul>
<hr>
<ul>
<li><strong>Baidu 特征最强</strong>：实验证明，相比通用的 CLIP，这种在足球领域“深造”过的模型（Baidu Soccer Embeddings）作为视觉编码器效果最佳。</li>
<li><strong>数据 &gt; 模型</strong>：即便使用基础的 ResNet，只要用了对齐后的 MatchTime 数据集，表现甚至能超越在脏数据上跑的高级模型。</li>
</ul>
<hr>
<h2 id="第二篇论文-Towards-Universal-Soccer-Video-Understanding">第二篇论文 Towards Universal Soccer Video Understanding</h2>
<p>第二篇论文在第一篇论文的基础上提出了SoccerReplay-1988数据集。<br>
并且提出了足球专用的解码器MatchVison</p>
<h3 id="SoccerReplay-19886-Dataset">SoccerReplay-19886 Dataset</h3>
<p>这篇文章阐述了这个作者是如何做这个数据集的，将视频分为上下两场，从starting at kick off开始。并且采用第一篇文章的MatchTime的对齐方式，通过手动进行人工对齐</p>
<p><img src="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/image-5.png" alt="alt text"></p>
<h3 id="对于模型我自己的理解">对于模型我自己的理解:</h3>
<p>本质上就是一个改进的video transformer</p>
<h4 id="Token-Embedding">Token Embedding</h4>
<p><strong>空间切分：</strong> 每一帧图像 $ i $ 被切分成 $ M $ 个不重叠的小方块（Patches）。这就像把一张照片剪成方格阵列。</p>
<p><strong>线性映射 ($\Phi_{Emb}$)：</strong> 每个小方块被拉平并转换成一个维度为 $D$ 的向量。</p>
<p><strong>双重位置编码 (Position Embedding)：</strong> 这是关键。</p>
<ul>
<li><strong>空间位置编码 ($e_s^{pos}$)</strong>：告诉模型这个方块在画面的哪个位置（左上还是右下）。</li>
<li><strong>时间位置编码 ($e_t^{pos}$)</strong>：在处理完整个视频序列后叠加，告诉模型这一组特征属于视频的第几秒。</li>
</ul>
<p><strong>[CLS] 标记：</strong> 每一帧都会加入一个特殊的 <code>[cls]</code> 标记，专门用来汇总这一帧的全局信息。</p>
<h4 id="时空注意力模块">时空注意力模块</h4>
<p><strong>时间自注意力 ($\phi_t$)：</strong></p>
<ul>
<li><strong>操作：</strong> 只在不同帧的<strong>相同空间位置</strong>的 Token 之间进行计算。</li>
<li><strong>目的：</strong> 追踪动作。例如，第1帧里的足球在左边，第2帧里的足球移动到了中间，时间注意力负责捕捉这个“移动”轨迹。</li>
</ul>
<p><strong>空间自注意力 ($\phi_s$)：</strong></p>
<ul>
<li><strong>操作：</strong> 只在<strong>同一帧内部</strong>的不同 Token 之间进行计算。</li>
<li><strong>目的：</strong> 理解布局。例如，识别出这一帧画面里哪是球员、哪是球门、哪是裁判。</li>
</ul>
<p><strong>交替堆叠 ($K$ 次)：</strong> 通过多次交替循环，模型既能看清每一帧的细节，又能理解动作在时间上的逻辑。</p>
<h4 id="聚合层-Aggregation-Layer">聚合层(Aggregation Layer)</h4>
<p>在经过复杂的注意力计算后，模型需要把海量的数据“浓缩”成一个简洁的特征向量，供下游任务使用。</p>
<ul>
<li><strong>空间聚合：</strong> 利用聚合层 $\Phi_{Agg}$，将每一帧中散落在各个 Patch 里的信息，全部压缩到该帧的 <code>[cls]</code> 标记中（得到 $\hat{F}_i^{CLS}$）。</li>
<li><strong>最终表示 ($F_V$)：</strong> 将所有帧的 <code>[cls]</code> 标记拼接起来。
<ul>
<li><strong>结果：</strong> 得到的 $F_V$ 是一个矩阵，它每一行代表一帧的精华，整组矩阵代表了整个视频片段的精华。</li>
</ul>
</li>
</ul>
<h3 id="预训练层">预训练层</h3>
<h3 id="监督分类-Supervised-Classification-mathcal-L-sup"><strong>监督分类 (Supervised Classification, $\mathcal{L}_{sup}$)</strong></h3>
<ul>
<li><strong>做法：</strong> 将提取出的视频特征 $F_V$ 通过一个<strong>时间自注意力层</strong>，汇总到一个可学习的 <code>[cls]</code> 标记中。</li>
<li><strong>计算：</strong> 这个标记被输入线性分类器，使用<strong>交叉熵损失 (Cross-Entropy Loss)</strong> 进行训练。</li>
<li><strong>目的：</strong> 让模型学会“看图识事”，即直接根据画面判断这是进球还是犯规。</li>
</ul>
<h3 id="视频-语言对比学习-Video-Language-Contrastive-Learning-mathcal-L-contra"><strong>视频-语言对比学习 (Video-Language Contrastive Learning, $\mathcal{L}_{contra}$)</strong></h3>
<ul>
<li><strong>做法：</strong> 对视频特征进行平均池化得到 $F_V^{Avg}$，同时用文本编码器处理解说词 $C$。</li>
<li><strong>创新点：</strong> 借鉴了 <strong>SigLIP</strong> 的损失函数。</li>
<li><strong>正样本优化：</strong> 针对足球比赛中经常出现高度相似的解说（如“比赛开始”），模型将同一批次中相似度高的文本都视为正样本，增强了鲁棒性。</li>
<li><strong>目的：</strong> 建立视觉与文本的语义联系，为下游的解说生成任务打好基础。</li>
</ul>
<h3 id="疑问：">疑问：</h3>
<h4 id="为什么是监督分类？">为什么是监督分类？</h4>
<h3 id="1-足球语义的复杂性与明确性">1. 足球语义的复杂性与明确性</h3>
<ul>
<li><strong>语义明确：</strong> 足球比赛中的关键事件（如进球、黄牌、换人）都有非常明确的官方定义和边界。</li>
<li><strong>监督优势：</strong> 监督分类通过使用专家标注的 <strong>Event Labels</strong>，能直接“教会”模型识别这些高层语义特征。相比之下，无监督学习（如传统的聚类或掩码建模）可能只会让模型学会识别“草坪是绿色的”或“球员在跑动”，而难以自发理解“这是一个越位”这种复杂的逻辑关系。</li>
</ul>
<h3 id="2-预训练目标的互补性">2. 预训练目标的互补性</h3>
<p>根据文本，MatchVision 并不是只用监督学习，而是采用了<strong>混合策略</strong>：</p>
<ul>
<li><strong>监督分类 ($\mathcal{L}_{sup}$)</strong>：负责建立<strong>视觉特征与官方动作标签</strong>的强关联。</li>
<li><strong>对比学习 ($\mathcal{L}_{contra}$)</strong>：这其实具有一定的“弱监督”或“自监督”性质，它通过**视频与解说词（Textual Commentaries）**的匹配，让模型学习更丰富的语言描述能力。</li>
<li><strong>结合效果：</strong> 监督分类提供了“硬准则”（这是什么动作），而对比学习提供了“软语义”（这个动作怎么描述）。</li>
</ul>
<h3 id="3-提升特征的判别力-Discriminative-Power">3. 提升特征的判别力 (Discriminative Power)</h3>
<ul>
<li><strong>类内与类间差异：</strong> 足球视频中，很多动作看起来极其相似（例如，普通的传球和助攻传球在视觉上可能只有微小区别）。</li>
<li><strong>监督的作用：</strong> 使用交叉熵损失（Cross-Entropy Loss）的监督训练，会强制模型在特征空间中拉开不同事件类别的距离，从而在下游任务（如犯规识别）中表现得更精准。</li>
</ul>
<h3 id="4-行业数据集的现状">4. 行业数据集的现状</h3>
<ul>
<li><strong>标注资源：</strong> 足球领域拥有如 SoccerNet 这样大规模且高质量的标注数据集。</li>
<li><strong>效率考量：</strong> 既然已经有了现成的“正确答案（Labels）”，直接使用监督学习进行预训练，比让模型在海量无标注视频中漫无目的地探索（无监督）要高效得多。</li>
</ul>
<h4 id="什么是cls和cmt">什么是cls和cmt</h4>
<h2 id="1-CLS-Event-Classification-事件分类">1. CLS (Event Classification - 事件分类)</h2>
<p><strong>CLS</strong> 是 <strong>Classification</strong> 的缩写，主要负责“看图识事”，即识别视频中发生了什么特定事件。</p>
<ul>
<li><strong>核心功能：</strong> 将输入的足球视频片段归类为预定义的事件标签，例如“进球”、“角球”、“黄牌”或“换人”。</li>
<li><strong>实现机制：</strong> * 模型会引入一个可学习的 <strong>[cls] token</strong>，通过<strong>时间自注意力机制</strong>（Temporal Self-attention）汇总整段视频的时空特征。
<ul>
<li>该特征随后被送入一个<strong>线性分类器</strong>（Linear Classifier）进行处理。</li>
</ul>
</li>
<li><strong>输出结果：</strong> 给出各个事件类别的概率分布，通常选取概率最高的一个作为最终判定结果（如：Type: “Yellow card”）。</li>
</ul>
<hr>
<h2 id="2-CMT-Commentary-Generation-解说生成">2. CMT (Commentary Generation - 解说生成)</h2>
<p><strong>CMT</strong> 是 <strong>Commentary</strong> 的缩写，主要负责“见图说话”，即生成像专业解说员一样的自然语言描述。</p>
<ul>
<li><strong>核心功能：</strong> 自动为视频片段编写一段符合赛况的叙述性文字。</li>
<li><strong>实现机制：</strong>
<ul>
<li>使用 <strong>Perceiver 聚合器</strong> 将复杂的视觉特征浓缩，并通过 <strong>MLP</strong> 映射为<strong>前缀嵌入</strong>（Prefix Embeddings）。</li>
<li>这些视觉嵌入被输入到**大语言模型（LLM）**中，引导 LLM 根据画面内容生成文本。</li>
</ul>
</li>
<li><strong>输出结果：</strong> 一段完整的句子，例如：“[REFEREE] shows a yellow card to [PLAYER]…”。</li>
</ul>
<h3 id="下游任务层">下游任务层</h3>
<p>预训练完成后，视觉编码器被“冻结”或作为骨干网络，通过不同的<strong>预测头 ($\Psi$)</strong> 来适配具体任务：</p>
<h3 id="事件分类-Psi-cls"><strong>事件分类 ($\Psi_{cls}$)</strong></h3>
<ul>
<li><strong>机制：</strong> 结构与预训练的监督学习类似，使用时间自注意力聚合特征。</li>
<li><strong>训练逻辑：</strong> 在<strong>冻结视觉编码器</strong>的情况下，仅训练线性分类器。</li>
<li><strong>输出：</strong> 给出视频属于哪种事件（如：角球、黄牌）的概率分布。</li>
</ul>
<h3 id="解说生成-Psi-Cmt"><strong>解说生成 ($\Psi_{Cmt}$)</strong></h3>
<ul>
<li>
<p><strong>核心组件：</strong> <strong>Perceiver 聚合器</strong> + <strong>MLP</strong> + <strong>LLM（大语言模型）</strong>。</p>
</li>
<li>
<p>流程： 1. Perceiver 将海量的视觉特征压缩。</p>
<p>\2. MLP 将其映射为 LLM 能听懂的“前缀嵌入（Prefix Embeddings）”。</p>
<p>\3. LLM 根据这些“视觉前缀”像写作文一样生成解说词。</p>
</li>
<li>
<p><strong>损失函数：</strong> 使用负对数似然损失（Next-Token Prediction）。</p>
</li>
</ul>
<h3 id="犯规识别-Psi-Foul"><strong>犯规识别 ($\Psi_{Foul}$)</strong></h3>
<ul>
<li><strong>输入：</strong> 足球比赛中常见的**多视角（Multi-view）**视频。</li>
<li><strong>处理：</strong> 使用池化技术（Max/Avg Pooling）将多视角特征整合为一个向量。</li>
<li><strong>双任务输出：</strong> 使用一个共享的 MLP 接两个分类器，同时预测：
<ol>
<li><strong>犯规类型</strong>（如：铲球犯规、手球等，共 8 种）。</li>
<li><strong>严重程度</strong>（如：口头警告、黄牌、红牌等，共 4 级）。</li>
</ol>
</li>
</ul>
<p><strong>为什么要使用MLP</strong></p>
<p>实现跨模态的特征对齐，不需要更强大的模型，简单的MLP足够胜任模态对齐工作</p>
<h3 id="实验部分">实验部分</h3>
<p>基于他上面自己的soccer Replay 1988数据集进行实验</p>
<p>MatchVision在分类这个任务是达到了**82.5%**的准确率</p>
<p>证明对比学习比监督学习的效果更好</p>
<p>并且MatchVision在foul recongition方面，即使冻结了视觉编码器，也和顶尖模型不相上下</p>
<h3 id="最后部分">最后部分</h3>
<p>使用了LoRA技术调教LLM</p>
<p>这篇论文有三个比较大的贡献</p>
<p><strong>新资源</strong>：造出了迄今为止最大的足球数据集 <strong>SoccerReplay-1988</strong>。</p>
<p><strong>新模型</strong>：开发了专门针对足球时空特征的编码器 <strong>MatchVision</strong>。</p>
<p><strong>新标杆</strong>：在分类、解说、犯规识别等多个任务上都达到了<strong>世界领先水平 (SOTA)</strong>。</p>
<h2 id="Multi-Agent-System-for-Comprehensive-Soccer-Understanding">Multi-Agent System for Comprehensive Soccer Understanding</h2>
<h3 id="引言">引言</h3>
<p>论文在引言部分介绍了现在的研究在足球理解研究的一些挑战</p>
<p>在推理任务上比较的局限（局限于视觉分析而缺少了推理）</p>
<p>以及模型过于的碎片化和专家化</p>
<p><strong>这篇文章主要有四个贡献</strong></p>
<p><strong>构建了 SoccerWiki 知识库</strong>：这是第一个大规模的多模态足球知识库，集成了关于球员、球队、裁判和场地的丰富领域知识，旨在支持知识驱动的推理任务 。该库包含 9,471 名球员、266 支球队、202 名裁判和 235 个场地的详细信息 。</p>
<p><strong>建立了 SoccerBench 基准测试集</strong>：这是目前最大且最全面的足球领域专项基准 。它通过自动化的数据策划和人工验证构建，包含约 1 万个多模态（文本、图像、视频）选择题对，涵盖了背景知识、比赛局势识别、犯规识别等 13 项不同的足球分析任务 。</p>
<p><strong>开发了 SoccerAgent 多智能体系统</strong>：这是一种新型的多智能体协作系统，通过将复杂的足球问题分解为多个可执行的子任务来解决问题 。它利用了 SoccerWiki 的领域专家知识，并能够调用 18 个专项工具进行协作推理 。</p>
<p><strong>进行了广泛的评估与对比</strong>：作者在 SoccerBench 上将 SoccerAgent 与 11 种代表性的多模态大语言模型（MLLMs，如 GPT-4o、Claude 3.7、Gemini 2.0 等）进行了深入对比 。评估结果突显了该智能体系统在处理复杂、知识密集型足球任务中的优越性 。101</p>
<h3 id="介绍soccerBench">介绍soccerBench</h3>
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>包含任务 (Index)</strong></th>
<th><strong>考查重点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>纯文本推理</strong> (TextQA)</td>
<td><strong>Q1</strong> 背景知识, <strong>Q2</strong> 比赛局势</td>
<td>考查模型是否掌握了球员历史、转会、比赛战术等“足球常识”。</td>
</tr>
<tr>
<td><strong>图像视觉感知</strong> (ImageQA)</td>
<td><strong>Q3</strong> 相机状态分类, <strong>Q4</strong> 图片背景知识, <strong>Q5</strong> 球衣号码识别, <strong>Q6</strong> 比分与时间识别</td>
<td>考查模型对单张转播截图的解析力，例如识别“这是哪场比赛”、“这是几号球员”。</td>
</tr>
<tr>
<td><strong>视频动态分析</strong> (VideoQA)</td>
<td><strong>Q7</strong> 相机切换, <strong>Q8</strong> 回放定位, <strong>Q9</strong> 动作分类, <strong>Q10/Q11</strong> 评论生成与理解, <strong>Q12</strong> 球衣颜色识别, <strong>Q13</strong> 多视角犯规识别</td>
<td><strong>最难的部分</strong>。考查模型能否理解动作的连贯性，并根据规则做出裁判级别的判断（如 Q13 判定是否犯规）。</td>
</tr>
</tbody>
</table>
<h3 id="研究动机">研究动机</h3>
<p>作者认为目前足球AI时效性不足，评价碎片化</p>
<p>作者构建了SoccerWIKI，并且在此基础上构建了SoccerBench</p>
<h4 id="Data-Curation">Data Curation</h4>
<p>团队采用不同的策略生成原始问答对（模版生成，大模型生成）</p>
<p>并且转化成四选一的选择题</p>
<p>最后通过自动化合成再经过人工筛选，组成了<strong>SoccerBench</strong></p>
<h3 id="SoccerAgent">SoccerAgent</h3>
<p><img src="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/C:%5CUsers%5Cyunan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20251225220605344.png" alt="image-20251225220605344"></p>
<p>论文的核心部分</p>
<h4 id="基于DeepSeek-V3的主模块协同工作">基于DeepSeek-V3的主模块协同工作</h4>
<p><strong>规划者 ($\mathcal{A}_{plan}$)</strong>：负责“思考”。它接收问题后，并不直接回答，而是分析需要哪些步骤，从工具包里挑选出最合适的<strong>工具链</strong>。</p>
<p><strong>执行者 ($\mathcal{A}_{exec}$)</strong>：负责“动手”。它按照规划好的顺序，一个接一个地运行工具。每一步都会参考之前的执行历史（$\mathcal{H}_{i}$），从而实现上下文感知的自适应调整。</p>
<h4 id="ToolBox">ToolBox</h4>
<p><strong>12 个足球专项工具</strong>：</p>
<p><strong>基础分析</strong>：动作分类器、评论生成 。</p>
<p><strong>检索专家</strong>：比赛搜索、比赛历史/信息检索、<strong>人脸识别</strong>（从 SoccerWiki 匹配球员） 。</p>
<p><strong>感知专家</strong>：相机状态检测、<strong>球衣号码/颜色识别</strong>、比分和时间识别 。</p>
<p><strong>高级裁判</strong>：<strong>犯规识别</strong>（通过多视角投票机制模拟 VAR）和回放定位 。</p>
<p><strong>6 个通用解析工具</strong>：</p>
<p>包括<strong>帧选择</strong>（将视频转为关键帧）、语义分割（定位特定物体）、实体搜索和文本检索等 。</p>
<h3 id="实验部分-2">实验部分</h3>
<p>比较重点的：我认为是容错能力</p>
<p><strong>自主调整：</strong> 执行者 ($\mathcal{A}_{exec}$) 在发现第一步失败后，并没有卡死，而是根据历史上下文自主调整策略，改用“比赛搜索”工具成功找回了所需信息 。</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" style="color: #00a596">论文笔记</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/MatchTime/" style="color: #00bcd4">MatchTime</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/SoccerNet/" style="color: #03a9f4">SoccerNet</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E8%B6%B3%E7%90%83AI/" style="color: #00a596">足球AI</a>
        </span>
        
    </div>
    <a href="/2025/12/23/%E5%88%AB%E5%86%8D%E8%AF%B4-AI-%E4%B8%8D%E6%87%82%E7%90%83%EF%BC%9AMatchTime-%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E6%B7%B1%E5%BA%A6%E7%AC%94%E8%AE%B0/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/">
        <h2 class="post-title">样式迁移</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/11/20
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="简介">简介</h2>
<p>样式迁移：将一个图片的风格样式转移到另一个图片上</p>
<p>最早的样式迁移：基于CNN的样式迁移<br>
基于CNN的样式迁移<br>
<img src="/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/image-4.png" alt="alt text"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="color: #ffa2c4">深度学习</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/" style="color: #03a9f4">样式迁移</a>
        </span>
        
    </div>
    <a href="/2025/11/20/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/11/11/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%AF%BB%E6%89%BE%E7%BB%8F%E9%AA%8C/">
        <h2 class="post-title">科研实习寻找经验</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/11/11
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="USTC-张少峰老师">USTC 张少峰老师</h2>
<p>投递的USTC人工智能与大数据实验室，张少峰老师，未被回复</p>
<h1>10 月 28 日</h1>
<p>再度投递，依旧未回复</p>
<h1>11 月 11 日</h1>
<p>找到的招科研实习的老师</p>
<h2 id="SJTU-张林峰-老师">SJTU 张林峰 老师</h2>
<p>研究方向:Efficient AI<br>
招聘界面:<br>
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1910049209664660559">https://zhuanlan.zhihu.com/p/1910049209664660559</a><br>
实验室主页:<br>
www.zhanglinfeng.tech<br>
老师邮箱:zhanglinfeng@sjtu.edu.cn</p>
<h2 id="NJU-刘佳恒老师">NJU 刘佳恒老师</h2>
<p>南京大学-大规模智能与知识实验室（NJU-LINK, Large-scale Intelligence and Knowledge Lab）<br>
老师邮箱:211300096@smail.nju.edu.cn<br>
招聘界面:<br>
<a target="_blank" rel="noopener" href="https://www.nju-link.com/zh/post/25-7-21-recruit2/">https://www.nju-link.com/zh/post/25-7-21-recruit2/</a></p>
<h2 id="RUC-金琴老师">RUC 金琴老师</h2>
<p>投递邮箱:aim3.ruc@gmail.com<br>
邮件中附上简历、兴趣方向和预期的实习时间等信息<br>
实验室主页:<br>
<a target="_blank" rel="noopener" href="https://www.ruc-aim3.com/">https://www.ruc-aim3.com/</a><br>
招聘界面:<br>
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1917932252114973992">https://zhuanlan.zhihu.com/p/1917932252114973992</a></p>
<h2 id="西湖大学-Westlake-university">西湖大学 Westlake university</h2>
<p>LINs Lab<br>
实验室主页:<br>
<a target="_blank" rel="noopener" href="https://lins-lab.github.io/">https://lins-lab.github.io/</a><br>
招聘界面:<br>
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/690440155">https://zhuanlan.zhihu.com/p/690440155</a></p>
<h1>11 月 13日</h1>
<h2 id="NJU-范崎老师">NJU 范崎老师</h2>
<p>智能科学与技术学院<br>
申请要求：</p>
<ol>
<li>热爱科研（最最重要！）</li>
<li>有一定的相关基础</li>
<li>在读本科生、硕士生、博士生均可。也欢迎已经毕业的朋友进行科研合作</li>
<li>线下线上均可</li>
</ol>
<p>联系方式：fanqi@nju.edu.cn<br>
请附带简历和成绩单</p>
<h1>已经错过时间但是可以去了解的计划:</h1>
<h2 id="西湖大学-暑期研究计划">西湖大学 暑期研究计划</h2>
<h2 id="中国科学院大学-大学生创新实践训练集计划">中国科学院大学 大学生创新实践训练集计划</h2>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%A7%91%E7%A0%94/" style="color: #03a9f4">科研</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E5%AE%9E%E4%B9%A0/" style="color: #00bcd4">实习</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E7%BB%8F%E9%AA%8C/" style="color: #03a9f4">经验</a>
        </span>
        
    </div>
    <a href="/2025/11/11/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%AF%BB%E6%89%BE%E7%BB%8F%E9%AA%8C/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">
        <h2 class="post-title">计算机网络</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/5/9
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h1>第一章</h1>
<h2 id="1-1">1.1</h2>
<h3 id="1-1-1-计算机网络的概念">1.1_1 计算机网络的概念</h3>
<p><strong>什么是计算机网络</strong><br>
计算机网络是一个将众多分散的，自治的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。<br>
<strong>计算机网络vs互连网vs互联网</strong><br>
<strong>计算机网络</strong>:由若干结点和连接这些节点的链路组成的。<br>
结点可以是:计算机，集线器，交换机，路由器。<br>
链路可以是有线链路，无线链路。<br>
<strong>互连网</strong>:若干个计算机网络通过路由器连接起来的网络。<br>
ISP：互联网服务提供商<br>
<strong>互联网</strong>：由多个互连网通过路由器连接起来的网络。<br>
<strong>TCP/IP协议：</strong><br>
互联网必须用TCP/IP协议，而互连网则可以用不同的协议。</p>
<p><img src="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/C:%5CUsers%5Cyunan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250509171848595.png" alt="image-20250509171848595"></p>
<h3 id="1-1-2-计算机网络的组成和功能">1.1_2 计算机网络的组成和功能</h3>
<p><img src="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/C:%5CUsers%5Cyunan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250509172529911.png" alt="image-20250509172529911"></p>
<p><img src="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/C:%5CUsers%5Cyunan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250509172836955.png" alt="image-20250509172836955"></p>
<p><img src="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/C:%5CUsers%5Cyunan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250509172909091.png" alt="image-20250509172909091"></p>
<p>计算机网络的功能</p>
<p><img src="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/C:%5CUsers%5Cyunan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250509181807005.png" alt="image-20250509181807005"></p>
<h3 id="1-1-3-1-电路交换-报文交换-分组交换">1.1_3_1 电路交换 报文交换 分组交换</h3>
<p><strong>电路交换</strong>:通过物理线路的连接，动态的分配传输线路资源</p>
<p><strong>电路交换的优点：</strong><br>
通信前从主叫端到被叫端建立一条专用的物理通路，在通信的全部时间内，两个用户始终占用端到端的线路资源。数据直送，传输速率高<br>
电路交换更适用于：低频次、大量地传输数据<br>
<strong>电路交换的缺点：</strong><br>
建立/释放连接，需长额外的时间开销</p>
<p><strong>报文交换:</strong></p>
<p><strong>报文交换的优点：</strong><br>
·通信前无需建立连接<br>
数据以“报文”为单位被交换节点间“存储转发”，通信线路可以灵活分配<br>
在通信时间内，两个用户无需独占一整条物理线路。相比于电路交换，线路利用率高<br>
交换节点支持“差错控制”（通过校验技术）<br>
<strong>报文交换的缺点：</strong><br>
报文不定长，不方便存储转发管理<br>
长报文的存储转发时间开销大、缓存开销大长报文容易出错，重传代价高</p>
<p>**分组交换:**将长报文的数据切成定长的数据</p>
<p><strong>分组交换的优点：</strong><br>
通信前无需建立连接<br>
数据以“分组”为单位被交换节点间“存储转发”，通信线路可以灵活分配<br>
在通信时间内，两个用户无需独占一整条物理线路。相比于电路交换，线路利用率高<br>
交换节点支持“差错控制”（通过校验技术)<br>
相比于报文交换，分组交换改进了如下问题：<br>
分组定长，方便存储转发管理<br>
分组的存储转发时间开销小、缓存开销小<br>
分组不易出错，重传代价低<br>
<strong>分组交换的缺点：</strong><br>
相比于报文交换，控制信息占比增加<br>
相比于电路交换，依然存在存储转发时延</p>
<p>虚电路交换</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="color: #03a9f4">学习笔记</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="color: #00a596">计算机网络</a>
        </span>
        
    </div>
    <a href="/2025/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/04/28/ResNet/">
        <h2 class="post-title">ResNet</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/4/28
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="核心思想">核心思想</h2>
<p>加更多层不会让你变差</p>
<h2 id="残差块">残差块</h2>
<p>f(x) = x + g(x)</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="color: #ff7d73">深度学习</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/ResNet/" style="color: #03a9f4">ResNet</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="color: #ffa2c4">神经网络</a>
        </span>
        
    </div>
    <a href="/2025/04/28/ResNet/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/04/28/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/">
        <h2 class="post-title">批量归一化</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/4/28
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="问题分析">问题分析</h2>
<p>损失出现在最后，后面的层训练较快，数据在最底部。</p>
<p>底部的层训练较慢，底部层一变化，所有都得跟着变，最后的那些层需要重新学习多次，导致收敛变慢。<br>
底部的层训练较慢<br>
底部层一变化，所有都得跟着变<br>
最后的那些层需要重新学习多次<br>
导致收敛变慢</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="color: #00bcd4">深度学习</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/" style="color: #00a596">批量归一化</a>
        </span>
        
    </div>
    <a href="/2025/04/28/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/">
        <h2 class="post-title">含并行连结的网络GoogLeNet</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/4/28
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="GoogLeNet">GoogLeNet</h2>
<p>第一个可以做到超过100层的卷积神经网络，致敬LeNet</p>
<h3 id="Inception块">Inception块</h3>
<p>使用不同窗口大小的卷积层<br>
致敬LeNet<br>
Inception块:<br>
使用不同窗口大小的卷积层<br>
<img src="/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/image-2.png" alt="alt text"></p>
<p>GoogLeNet<br>
<img src="/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/image-3.png" alt="alt text"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="color: #ffa2c4">深度学习</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="color: #03a9f4">神经网络</a>
        </span>
        
        <span class="tag">
            
            <a href="/tags/GoogLeNet/" style="color: #ff7d73">GoogLeNet</a>
        </span>
        
    </div>
    <a href="/2025/04/28/%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9CGoogLeNet/" class="go-post">阅读全文</a>
</div>


        <div class="page-current">
    
    <span class="current">1</span>
    
    <a class="page-num" href="/page/2">
        2
    </a>
    
    
    <a class="page-num" href="/page/3">
        3
    </a>
    
    
    <span class="page-omit">...</span>
    <a class="page-num" href="/page/4">4</a>
    
    
    <a class="page-num" href="/page/2/">
        <i class="fa-solid fa-caret-right fa-fw"></i>
    </a>
    
</div>

    </div>
    
    <div id="home-card">
        <div id="card-style">
    <div id="card-div">
        <div class="avatar">
            <img src="/images/avatar.jpg" alt="avatar" />
        </div>
        <div class="name">Izumi Sagiri</div>
        <div class="description">
            <p>Description<br>
我永远喜欢和泉纱雾</p>

        </div>
        
        
        <div class="friend-links">
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://argvchs.github.io">Argvchs</a>
            </div>
            
        </div>
        
    </div>
</div>

    </div>
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2025 Izumi Sagiri
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Izumi Sagiri
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
</body>
</html>
